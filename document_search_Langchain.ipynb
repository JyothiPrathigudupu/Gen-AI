{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c38c2b-88dc-4ba2-a590-e962edae712c",
   "metadata": {},
   "source": [
    "# Document Question and Answering using Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f7276-73e8-466c-acbc-6f7eb88eb2c9",
   "metadata": {},
   "source": [
    "# Set Key in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd4767c-b649-4cfb-a7eb-b971ceecfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "#os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624e6e3-f096-4243-b099-5c8caa47fec8",
   "metadata": {},
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01c2206-6914-41f4-a104-c808ed6a63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7cfe68-f512-4a64-9eab-0a44d1b48850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16f63f4-f439-40df-ae18-1732819c0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = PyPDFDirectoryLoader(\"C:/Users/nr802/Downloads/GenAI Projects/RESUMESP\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2d1753-63e9-41f8-85ee-f416669bb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a6e20-39eb-446f-a5a0-dc416cd7a2ad",
   "metadata": {},
   "source": [
    "# Initiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c98206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_OpenAI in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain_OpenAI) (0.3.17)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain_OpenAI) (1.54.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain_OpenAI) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai<2.0.0,>=1.54.0->langchain_OpenAI) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken<1,>=0.7->langchain_OpenAI) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken<1,>=0.7->langchain_OpenAI) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_OpenAI) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_OpenAI) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_OpenAI) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_OpenAI) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_OpenAI) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain_OpenAI) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_OpenAI) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_OpenAI) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain_OpenAI) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f356b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "aiohappyeyeballs==2.4.3\n",
      "aiohttp==3.10.10\n",
      "aiosignal==1.3.1\n",
      "annotated-types==0.7.0\n",
      "anyio==4.4.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "async-timeout==4.0.3\n",
      "attrs==24.2.0\n",
      "babel==2.16.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "blinker==1.9.0\n",
      "blis==0.7.11\n",
      "catalogue==2.0.10\n",
      "catboost==1.2.7\n",
      "certifi==2024.8.30\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "cloudpathlib==0.19.0\n",
      "cloudpickle==3.0.0\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "confection==0.1.5\n",
      "contourpy==1.3.0\n",
      "cycler==0.12.1\n",
      "cymem==2.0.8\n",
      "dataclasses-json==0.6.7\n",
      "debugpy==1.8.2\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.14\n",
      "dirtyjson==1.0.8\n",
      "distro==1.9.0\n",
      "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
      "exceptiongroup==1.2.1\n",
      "executing==2.0.1\n",
      "fastapi==0.115.5\n",
      "fastjsonschema==2.20.0\n",
      "filelock==3.16.1\n",
      "filetype==1.2.0\n",
      "Flask==3.1.0\n",
      "flatbuffers==24.3.25\n",
      "fonttools==4.53.1\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.10.0\n",
      "funcy==2.0\n",
      "gast==0.6.0\n",
      "gensim==4.3.3\n",
      "google-pasta==0.2.0\n",
      "graphviz==0.20.3\n",
      "greenlet==3.1.1\n",
      "grpcio==1.66.1\n",
      "h11==0.14.0\n",
      "h5py==3.11.0\n",
      "httpcore==1.0.5\n",
      "httpx==0.27.2\n",
      "httpx-sse==0.4.0\n",
      "huggingface-hub==0.26.2\n",
      "idna==3.8\n",
      "imbalanced-learn==0.12.3\n",
      "imblearn==0.0\n",
      "ipykernel==6.29.5\n",
      "ipython==8.26.0\n",
      "ipywidgets==8.1.5\n",
      "isoduration==20.11.0\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "jiter==0.7.0\n",
      "joblib==1.4.2\n",
      "json5==0.9.25\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.2\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.5\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "jupyterlab_widgets==3.0.13\n",
      "keras==3.5.0\n",
      "kiwisolver==1.4.7\n",
      "langchain==0.3.7\n",
      "langchain-community==0.3.7\n",
      "langchain-core==0.3.17\n",
      "langchain-openai==0.2.8\n",
      "langchain-text-splitters==0.3.2\n",
      "langcodes==3.4.0\n",
      "langsmith==0.1.143\n",
      "language_data==1.2.0\n",
      "libclang==18.1.1\n",
      "lightgbm==4.5.0\n",
      "llama-cloud==0.1.4\n",
      "llama-index==0.11.22\n",
      "llama-index-agent-openai==0.3.4\n",
      "llama-index-cli==0.3.1\n",
      "llama-index-core==0.11.23\n",
      "llama-index-embeddings-openai==0.2.5\n",
      "llama-index-indices-managed-llama-cloud==0.4.0\n",
      "llama-index-legacy==0.9.48.post4\n",
      "llama-index-llms-openai==0.2.16\n",
      "llama-index-multi-modal-llms-openai==0.2.3\n",
      "llama-index-program-openai==0.2.0\n",
      "llama-index-question-gen-openai==0.2.0\n",
      "llama-index-readers-file==0.2.2\n",
      "llama-index-readers-llama-parse==0.3.0\n",
      "llama-parse==0.5.13\n",
      "llvmlite==0.43.0\n",
      "marisa-trie==1.2.0\n",
      "Markdown==3.7\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "marshmallow==3.23.1\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mistune==3.0.2\n",
      "ml-dtypes==0.4.0\n",
      "mpmath==1.3.0\n",
      "multidict==6.1.0\n",
      "murmurhash==1.0.10\n",
      "mypy-extensions==1.0.0\n",
      "namex==0.0.8\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "nltk==3.9.1\n",
      "notebook==7.2.2\n",
      "notebook_shim==0.2.4\n",
      "numba==0.60.0\n",
      "numexpr==2.10.1\n",
      "numpy==1.26.1\n",
      "openai==1.54.0\n",
      "opt-einsum==3.3.0\n",
      "optree==0.12.1\n",
      "orjson==3.10.11\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandas==2.2.2\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pillow==10.4.0\n",
      "platformdirs==4.2.2\n",
      "plotly==5.24.0\n",
      "preshed==3.0.9\n",
      "prometheus_client==0.20.0\n",
      "prompt_toolkit==3.0.47\n",
      "propcache==0.2.0\n",
      "protobuf==4.25.4\n",
      "psutil==6.0.0\n",
      "pure-eval==0.2.2\n",
      "pycparser==2.22\n",
      "pydantic==2.9.0\n",
      "pydantic-settings==2.6.1\n",
      "pydantic_core==2.23.2\n",
      "Pygments==2.18.0\n",
      "pyLDAvis==3.4.1\n",
      "pyparsing==3.1.4\n",
      "pypdf==4.3.1\n",
      "PyPDF2==3.0.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "python-json-logger==2.0.7\n",
      "python-multipart==0.0.17\n",
      "pytz==2024.1\n",
      "pywin32==306\n",
      "pywinpty==2.0.13\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.0.3\n",
      "referencing==0.35.1\n",
      "regex==2024.7.24\n",
      "requests==2.32.3\n",
      "requests-toolbelt==1.0.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.8.0\n",
      "rpds-py==0.20.0\n",
      "safetensors==0.4.5\n",
      "scikit-learn==1.5.2\n",
      "scipy==1.13.1\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.3\n",
      "shap==0.46.0\n",
      "shellingham==1.5.4\n",
      "six==1.16.0\n",
      "slicer==0.0.8\n",
      "smart-open==7.0.4\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "spacy==3.7.6\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "SQLAlchemy==2.0.35\n",
      "srsly==2.4.8\n",
      "stack-data==0.6.3\n",
      "starlette==0.41.2\n",
      "striprtf==0.0.26\n",
      "sympy==1.13.1\n",
      "tenacity==8.5.0\n",
      "tensorboard==2.18.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow-io-gcs-filesystem==0.31.0\n",
      "termcolor==2.4.0\n",
      "terminado==0.18.1\n",
      "textblob==0.18.0.post0\n",
      "thinc==8.2.5\n",
      "threadpoolctl==3.5.0\n",
      "tiktoken==0.8.0\n",
      "tinycss2==1.3.0\n",
      "tokenizers==0.20.3\n",
      "tomli==2.0.1\n",
      "torch==2.5.1\n",
      "tornado==6.4.1\n",
      "tqdm==4.66.5\n",
      "traitlets==5.14.3\n",
      "typer==0.12.5\n",
      "types-python-dateutil==2.9.0.20240906\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.1\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.2\n",
      "uvicorn==0.32.0\n",
      "wasabi==1.1.3\n",
      "wcwidth==0.2.13\n",
      "weasel==0.4.1\n",
      "webcolors==24.8.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "Werkzeug==3.1.3\n",
      "widgetsnbextension==4.0.13\n",
      "wordcloud==1.9.3\n",
      "wrapt==1.16.0\n",
      "xgboost==2.1.1\n",
      "yarl==1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a853082-1a24-43d3-99e2-309642c9559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68aeead-8049-4f13-b713-c6ba98dce4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a738645-4e74-40f9-a771-01e04b582292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==1.54.0 langchain-core==0.3.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4616a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.54.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.54.0)\n",
      "Requirement already satisfied: langchain-core==0.3.17 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.3.17)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (2.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai==1.54.0) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core==0.3.17) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core==0.3.17) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core==0.3.17) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core==0.3.17) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core==0.3.17) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai==1.54.0) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai==1.54.0) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai==1.54.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai==1.54.0) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.54.0) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.17) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.17) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.17) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.17) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1.9.0->openai==1.54.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1.9.0->openai==1.54.0) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic<3,>=1.9.0->openai==1.54.0) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>4->openai==1.54.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.17) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.17) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.54.0 langchain-core==0.3.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f9c44-e6d3-4ff5-83af-23231f3e1a49",
   "metadata": {},
   "source": [
    "# Initiate retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad92828-50af-4b19-9d4e-d4726b47a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489bb824-9b5f-48f6-b9eb-469ffd82d671",
   "metadata": {},
   "source": [
    "# Retrieve related documents from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc6beec-b422-4852-bc2f-b3235be0090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b322e975-05be-4bfa-a375-b811ba70a50b', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 1}, page_content='• HUMAN RESOURCE internship from “Yoursthatsenior”   \\n• CYBER SECURITY  internship from “ST7 surveillance solution”   \\n• DATA SCIENCE WITH AI  internship from “Quality Thought ”  \\n \\n \\n \\n            I am here to declare that all the information furnished about me is true to the best of my knowledge . \\n   \\n                                                                                                                                                            Bhagyavalli Kurmala  \\n                                                                                                                                                            Hyderabad  \\n CERTIFICATIONS  \\n \\nINTER NSHIPS  \\n \\nDeclarati on'),\n",
       " Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='8884d6d4-c840-4b05-af6a-a57cff66d84d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\KRISHNA CHAITANY RESUME 1.pdf', 'page': 1}, page_content='Skills Acquired : \\n Tools Known: \\n\\uf0b7 Microsoft Office Suite (Word, Excel, PowerPoint) \\n\\uf0b7 Chemdraw \\n\\uf0b7 Python Programming Language. \\n\\uf0b7 Python Libraries \\n\\uf0b7 Machine Learning \\n\\uf0b7 SQL (Structured Query Language) \\n \\n \\n \\n \\nPersonal Details: \\n \\nFirst Name: Gaddam \\nLast Name: Krishna Chaitanya. \\nFather’s Name: Gaddam Anandam. \\nGender: Male \\nLanguages Known: English, Telugu, Hindi. \\nPlace of Birth: Hyderabad, Telangana. \\nCountry of Birth: India \\nNationality: Indian \\n \\nDeclaration : \\n \\nI, Gaddam Krishna Chaitanya, hereby declare that the Information \\nfurnished above is true to the best of my knowledge and belief. \\n \\n \\nPlace: Hyderabad                                                                    Signature :'),\n",
       " Document(id='86080055-7ae8-474b-91c2-8c2f7810c78a', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mohit Resume.pdf', 'page': 1}, page_content='EXTRA CURRICULAR ACTIVITIES \\n\\uf0b7 Served as a Class Representative  \\n\\uf0b7 Lead  a  team for TECHNOSTAV - 2K23 with 200+ participants \\n \\nPERSONAL INFROMATION \\nDOB: 24/07/2002 \\nMarital Status: Unmarried \\nNationality: Indian \\n \\nLANGUAGES KNOWN \\nEnglish \\nTelugu \\nHindi \\nDECLARATION  \\nI hereby declare that all the information given above is true and correct to the best of my knowledge. \\n \\n \\n \\n \\n \\nMOHIT SUKUMAR SONGA')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide names of all people?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54648d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='ab5f51ec-b5c5-48a6-961f-fc8af108e86b', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Om Shewale Resum.pdf', 'page': 0}, page_content='influencing launch success rates.\\nSKILLS\\n•Programming Languages: Python, SQL, HTML, CSS\\n•Web Technologies: HTML, CSS\\n•Database Systems: MySQL, SQLite\\n•Data Science & Machine Learning: Pandas, NumPy, Matplotlib, Scikit-learn, Power BI, Excel\\n•DevOps & Version Control: Git, GitHub\\n•Specialized Area: Data Science, Machine Learning, Data Analytics, Predictive Modeling\\n•Mathematical & Statistical Tools: Statistics, Probability, Linear Algebra\\n•Other Tools & Technologies: Microsoft Excel, Power BI\\n•Research Skills: Data Analysis, Model Development, Feature Engineering, Data Visualization\\nCERTIFICATIONS\\n•Hackerank Aug - 2024\\nADDITIONAL INFORMATION\\nLanguages: English , Hindi , Marathi\\nInterests: Machine Learning and AI ,Data Science and Analytics , Natural Language Processing (NLP) , Predictive\\nModeling and Forecasting'),\n",
       " Document(id='1db1aebf-f449-4974-af90-f0937cee046d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content='TECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.'),\n",
       " Document(id='e47da941-0d85-4a07-8bed-f6c0cc6d5643', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 0}, page_content='Prathigudupu  Jyothi  \\n \\n     (+91)  9347792387                                                             https://www.linkedin.com/in/jyothi -prathigudupu -\\n140715289   \\njyothiprathigudupu@gmail.com  https://github.com/JyothiPrathigudupu  \\n  \\n \\n   CAREER  OBJECTIVE  \\nSeeking  a data scientist  role at an innovative  firm valuing  analytics,  coding,  and passion  for data. Eager  to tackle  \\nbig projects  with the latest  tech and enhance  skills  in statistics,  machine  learning,  Artificial  Intelligence  and data \\nvisualization. Ready to collaborate, address challenges, and drive data -informed decisions, with a commitment  \\nto continuous  learning.  \\n \\nTECHNICAL  SKILLS  \\n \\nPython  : Functions and Modules, Data Structures, OOPs, NumPy, Pandas , Matplotlib,  Seaborn,  \\nScikit -learn . \\nMachine  Learning  :  EDA,  Supervised  Learning,  Unsupervised  Learning,  Ensemble  Techniques,  Optimization     \\nTechniques,  Encoding  Techniques,  NLP,  Neural  Networks.  \\nDatabase  : SQL')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me data science skills of all people?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a317c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9c87205a-00ae-4cb4-92f9-ddcb471ff02d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 1}, page_content='• HUMAN RESOURCE internship from “Yoursthatsenior”   \\n• CYBER SECURITY  internship from “ST7 surveillance solution”   \\n• DATA SCIENCE WITH AI  internship from “Quality Thought ”  \\n \\n \\n \\n            I am here to declare that all the information furnished about me is true to the best of my knowledge . \\n   \\n                                                                                                                                                            Bhagyavalli Kurmala  \\n                                                                                                                                                            Hyderabad  \\n CERTIFICATIONS  \\n \\nINTER NSHIPS  \\n \\nDeclarati on'),\n",
       " Document(id='9b513598-3224-4022-ae46-80ea57f39fed', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content='TECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.'),\n",
       " Document(id='62e6fd16-0e48-41ab-9d07-b65e564aae91', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='37290953-ba93-47c0-9b4e-83b3e4fe6d22', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"integration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\")]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me interview questions based on resumes?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f594a4bd-fa56-4634-a5b4-3d307ef342e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'influencing launch success rates.\\nSKILLS\\n•Programming Languages: Python, SQL, HTML, CSS\\n•Web Technologies: HTML, CSS\\n•Database Systems: MySQL, SQLite\\n•Data Science & Machine Learning: Pandas, NumPy, Matplotlib, Scikit-learn, Power BI, Excel\\n•DevOps & Version Control: Git, GitHub\\n•Specialized Area: Data Science, Machine Learning, Data Analytics, Predictive Modeling\\n•Mathematical & Statistical Tools: Statistics, Probability, Linear Algebra\\n•Other Tools & Technologies: Microsoft Excel, Power BI\\n•Research Skills: Data Analysis, Model Development, Feature Engineering, Data Visualization\\nCERTIFICATIONS\\n•Hackerank Aug - 2024\\nADDITIONAL INFORMATION\\nLanguages: English , Hindi , Marathi\\nInterests: Machine Learning and AI ,Data Science and Analytics , Natural Language Processing (NLP) , Predictive\\nModeling and Forecasting'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56bf5535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='8c39247c-d49e-4c3a-b7b0-a35ea3918221', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"integration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\"),\n",
       " Document(id='1db1aebf-f449-4974-af90-f0937cee046d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content='TECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.'),\n",
       " Document(id='e47da941-0d85-4a07-8bed-f6c0cc6d5643', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 0}, page_content='Prathigudupu  Jyothi  \\n \\n     (+91)  9347792387                                                             https://www.linkedin.com/in/jyothi -prathigudupu -\\n140715289   \\njyothiprathigudupu@gmail.com  https://github.com/JyothiPrathigudupu  \\n  \\n \\n   CAREER  OBJECTIVE  \\nSeeking  a data scientist  role at an innovative  firm valuing  analytics,  coding,  and passion  for data. Eager  to tackle  \\nbig projects  with the latest  tech and enhance  skills  in statistics,  machine  learning,  Artificial  Intelligence  and data \\nvisualization. Ready to collaborate, address challenges, and drive data -informed decisions, with a commitment  \\nto continuous  learning.  \\n \\nTECHNICAL  SKILLS  \\n \\nPython  : Functions and Modules, Data Structures, OOPs, NumPy, Pandas , Matplotlib,  Seaborn,  \\nScikit -learn . \\nMachine  Learning  :  EDA,  Supervised  Learning,  Unsupervised  Learning,  Ensemble  Techniques,  Optimization     \\nTechniques,  Encoding  Techniques,  NLP,  Neural  Networks.  \\nDatabase  : SQL')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me interview questions for Data Science based on resumes?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d344260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='1db1aebf-f449-4974-af90-f0937cee046d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content='TECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.'),\n",
       " Document(id='071e6a3e-f45c-492d-87c3-7af0e2590bfa', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naliniresume.pdf', 'page': 0}, page_content=\"Nalini Banki  \\n 8328477005   bnalini 243gmail.com     \\n      https://www.linkedin.com/in/nalini -b-959506236/  \\nTechnical Skills   \\nLanguages and Data base: Python, Pandas, Num Py, SQL  \\nVisualization Tools : Power BI  \\nOther Skills : Advanced Excel, Data Analysis  \\nExperience/ Projects  \\n \\nRecession Analysis Project: Impact on the IT Industry  \\n• Conducted a comprehensive analysis of the IT sector's performance during economic recessions over the past \\ndecade.  \\n• Examined key economic indicators such as GDP and unemployment rates to identify trends.  \\n• Developed interactive dashboards in Power BI  for data visualization, resulting in a  90% stakeholder  \\nsatisf action rate based on feedback.  \\n• Provided strategic recommendations for IT companies , to navigate challenges during economic downturns.  \\n• Findings emphasized the importance of proactive strategies for business resilience . \\n \\nStock Market Portfolio Optimization\"),\n",
       " Document(id='8c39247c-d49e-4c3a-b7b0-a35ea3918221', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"integration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\")]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me interview questions for Data analyst based on resumes?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d93d50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c0250b04-a392-41aa-a37d-54d49c25451d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naga Chaitanya CV.pdf', 'page': 0}, page_content='2020 - 2024\\n2018 - 2020\\n2018V ankam Naga Chaitany a\\nSr Nagar Hy der abad T elangana\\n8978217941  | nagachaitany a1811@gmail.com\\nObjectiv e\\nRecent gr aduate seeking an entr y-le v el r ole in Data Science and Ar tiﬁcial Intelligence t o le v er age my analytical\\nskills and technical knowledge. Eager t o contribute t o inno v ativ e pr ojects, learn cutting-edge technologies, and\\ndeliv er data-driv en solutions while continuously gr owing and de v eloping my exper tise in the ﬁeld. P assionate\\nabout tr ansforming complex data int o actionable insights and suppor ting or ganizational success thr ough AI and\\nML applications\\nE ducation\\nDr .M.G.R E ducational and Reaser ch Institute\\nB T ech || Computer Science Engineering\\n8.54\\nSri Saty a Sai Jr College\\nIntermediate\\n9.31\\nZPHS High School\\nSecondar y E ducation\\n8.7\\nSkills\\nPr ogr amming languages : P ython || SQL || Object oriented pr ogr amming || Html & Css\\nLibr aries : P andas || Nump y || Matplotlib || seaborn'),\n",
       " Document(id='b322e975-05be-4bfa-a375-b811ba70a50b', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 1}, page_content='• HUMAN RESOURCE internship from “Yoursthatsenior”   \\n• CYBER SECURITY  internship from “ST7 surveillance solution”   \\n• DATA SCIENCE WITH AI  internship from “Quality Thought ”  \\n \\n \\n \\n            I am here to declare that all the information furnished about me is true to the best of my knowledge . \\n   \\n                                                                                                                                                            Bhagyavalli Kurmala  \\n                                                                                                                                                            Hyderabad  \\n CERTIFICATIONS  \\n \\nINTER NSHIPS  \\n \\nDeclarati on'),\n",
       " Document(id='071e6a3e-f45c-492d-87c3-7af0e2590bfa', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naliniresume.pdf', 'page': 0}, page_content=\"Nalini Banki  \\n 8328477005   bnalini 243gmail.com     \\n      https://www.linkedin.com/in/nalini -b-959506236/  \\nTechnical Skills   \\nLanguages and Data base: Python, Pandas, Num Py, SQL  \\nVisualization Tools : Power BI  \\nOther Skills : Advanced Excel, Data Analysis  \\nExperience/ Projects  \\n \\nRecession Analysis Project: Impact on the IT Industry  \\n• Conducted a comprehensive analysis of the IT sector's performance during economic recessions over the past \\ndecade.  \\n• Examined key economic indicators such as GDP and unemployment rates to identify trends.  \\n• Developed interactive dashboards in Power BI  for data visualization, resulting in a  90% stakeholder  \\nsatisf action rate based on feedback.  \\n• Provided strategic recommendations for IT companies , to navigate challenges during economic downturns.  \\n• Findings emphasized the importance of proactive strategies for business resilience . \\n \\nStock Market Portfolio Optimization\"),\n",
       " Document(id='21f9d757-17c5-4ca1-aaa6-f9938a790149', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Rajasri_Resume.pdf', 'page': 0}, page_content='Rajasri Gudikandula       \\nrajasrig.0101 @gmail.com | +91-9440693452  | Hyderabad , India  |www.linkedin.com/in/rajasri -gudikandula -a98548329  \\n \\n \\nA highly motivated and enthusiastic fresher with a strong passion for software development and a solid understanding \\nof programming fundame ntals, including Pytho n and data structures. A pply my academic knowledge and problem -\\nsolving skills in a practical, real -world setting. Committed to continuous learning and personal growth, with a keen \\ninterest in contributing to innovative projects.  Seeking an entry -level position to begin my career in software \\ndevelopment and grow alongside a dynamic team.  \\n \\nSkills:  \\n  Python    : Pandas, NumPy, Matplotlib  \\n  OOP s     : Inheritance, Polymorphism, Encapsulation, Object, Class, Abstraction.  \\n  SQL       : Data Types, Functions, Joins  \\n  Machine Learning  : Linear Regression, Logistic Regression, Decision Tree  \\n  Excel  \\n  PowerBI  \\n \\nCertifications:')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me experience persons name for Data analyst based on resumes?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56ffdcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b322e975-05be-4bfa-a375-b811ba70a50b', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 1}, page_content='• HUMAN RESOURCE internship from “Yoursthatsenior”   \\n• CYBER SECURITY  internship from “ST7 surveillance solution”   \\n• DATA SCIENCE WITH AI  internship from “Quality Thought ”  \\n \\n \\n \\n            I am here to declare that all the information furnished about me is true to the best of my knowledge . \\n   \\n                                                                                                                                                            Bhagyavalli Kurmala  \\n                                                                                                                                                            Hyderabad  \\n CERTIFICATIONS  \\n \\nINTER NSHIPS  \\n \\nDeclarati on'),\n",
       " Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='bcd477ea-e20b-459e-9927-f96750e986ab', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 0}, page_content='During  2018  to 2020  from Sri Chaithanya  Junior  College,  Repalle.  \\n \\n10th Standard  9.3 CGPA  \\nDuring  2017 -2018  from Vikas  High  School,  Nizampatnam.  \\n \\nINTERNSHIP  AND TRAINING  \\n \\nTraining and Internship on Data  Science  with  Generative -AI (June -Dec 2024 -till date)  \\nQuality  Thought  Infosystems  India  (P) Ltd. \\n \\nInternship  on VLSI  Design  using  Verilog  (Feb -Apr 2024 -till date)  \\nMaven  Silicon  Softech  Pvt. Ltd.  \\n \\nInternship  on Embedded  System  (May -July 2023 -till date)  \\nSun Square  Technologies  Pvt. Ltd'),\n",
       " Document(id='5157c173-5b2b-4cef-95fd-eeb6eb12a912', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Siva Rama Krishna.pdf', 'page': 1}, page_content='CERTIFICATES  \\n• Completed an Internship provided by AICTE  \\n• Published  a research paper titles “Pedi atric Healthcare Analysis Using Machine \\nLearning ” in IEEE Conference.  \\n• Published a research paper  titled \"Youtube Comment   Spam Detection with UI\" in  \\nIEEE  Conference.  \\nHOBBIES  \\n• Cricket.  \\n• Cooking.  \\n• Problem Solving.  \\n• Dancing.  \\nLANGUAGES  \\n• Telugu . \\n• English.  \\n• Tamil.')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"Provide me college names based on resumes?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e576ac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8c39247c-d49e-4c3a-b7b0-a35ea3918221', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"integration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\"),\n",
       " Document(id='e98f3658-1a58-44d1-8e36-27b203eafa43', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Kartik_Resume.pdf', 'page': 0}, page_content='Deep Learning           : CNNs, Natural Language Process  \\n  SQL                           : Data Types, Functions, Joins  \\n \\nCertifications:  \\nProgramming  with Python, Understanding  Incubation  and Entrepreneurship  (NPTEL),  PHP (National  Skill Training \\nInstitute), Data Science for Engineers.  \\nExperiences:  \\nDeepceptAI  Pvt. Ltd.,  Bangalore,  India  Nov 2023  – May  2024  \\nIntern  \\n \\nProjects :   \\n \\nPredictive Modeling with XGBoost and Logistic Regression  \\nThe implementation of predictive models using Logistic Regression and XGBoost classifiers. It includes data \\npreprocessing steps, model training, evaluation using metrics such as R², mean squared e rror, accuracy, and ROC AUC \\nscore. The notebook applies these models to binary classification tasks, compares their performance, and outputs \\npredictions . \\n \\nReal-time Ambulance  Detection  with the YOLOv7  COCO  Model .'),\n",
       " Document(id='14fbf1d8-96c5-409e-9ee4-b3297122dfdc', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content='Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis'),\n",
       " Document(id='a11bdf07-ddbd-4ef0-98b4-d9a4e8ae1894', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 0}, page_content='Machine  Learning  :  EDA,  Supervised  Learning,  Unsupervised  Learning,  Ensemble  Techniques,  Optimization     \\nTechniques,  Encoding  Techniques,  NLP,  Neural  Networks.  \\nDatabase  : SQL  \\nSoftware  Tools  : Visual  Studio,  Jupyter  Notebook,  Arduino.  \\nData  Analysis  Tools  : Excel,  Power  BI. \\nSpecialized  Area  : Data Science , Data  Analysis . \\nArea  of Interest  : Mathematics,  Statistics,  Data  Science,  Machine  Learning  & Digital  Electronics.  \\nOffice Skills               : MS Word, PowerPoint . \\n \\n \\n \\n \\nEDUCATIONAL  QUALIFICATIONS  \\n \\nB. Tech [Electronics  & Communication  Engineering]  8.11 CGPA  \\nDuring  2020  to 2024  from  Chirala  Engineering  College,  Chirala. (JNTUK)  \\n \\nIntermediate  [Maths,  Physics  & Chemistry]  9.5 CGPA  \\nDuring  2018  to 2020  from Sri Chaithanya  Junior  College,  Repalle.  \\n \\n10th Standard  9.3 CGPA  \\nDuring  2017 -2018  from Vikas  High  School,  Nizampatnam.  \\n \\nINTERNSHIP  AND TRAINING')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"How can vector embeddings help in searching and matching resumes with job descriptions?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afe2bdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1db1aebf-f449-4974-af90-f0937cee046d', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content='TECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.'),\n",
       " Document(id='ab5f51ec-b5c5-48a6-961f-fc8af108e86b', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Om Shewale Resum.pdf', 'page': 0}, page_content='influencing launch success rates.\\nSKILLS\\n•Programming Languages: Python, SQL, HTML, CSS\\n•Web Technologies: HTML, CSS\\n•Database Systems: MySQL, SQLite\\n•Data Science & Machine Learning: Pandas, NumPy, Matplotlib, Scikit-learn, Power BI, Excel\\n•DevOps & Version Control: Git, GitHub\\n•Specialized Area: Data Science, Machine Learning, Data Analytics, Predictive Modeling\\n•Mathematical & Statistical Tools: Statistics, Probability, Linear Algebra\\n•Other Tools & Technologies: Microsoft Excel, Power BI\\n•Research Skills: Data Analysis, Model Development, Feature Engineering, Data Visualization\\nCERTIFICATIONS\\n•Hackerank Aug - 2024\\nADDITIONAL INFORMATION\\nLanguages: English , Hindi , Marathi\\nInterests: Machine Learning and AI ,Data Science and Analytics , Natural Language Processing (NLP) , Predictive\\nModeling and Forecasting'),\n",
       " Document(id='7d7d8a5c-a2c5-4ddd-bf42-dfd1067bc4a0', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 1}, page_content='learning models and optimized them for improved accuracy . \\n \\nCERTIFICATIONS  \\n \\n• Microsoft  365 Certified:  Teams  Administrator  Associate.  \\n• Certified  Embedded  System  Intern  from  Sun Square  Technologies.  \\n• Certified  CMOS  Digital  VLSI  Design  from  NPTEL.  \\n• Certified  Data Science  Intern  from  Pantech  e Learning.  \\n• Certified  VLSI  Design  using  Verilog  Intern  from  Maven  Silicon . \\n \\n \\nDECLARATION  \\nI hereby  declare  that the above -mentioned  details  are true to the best of my knowledge  and I am \\nresponsible  for any kind of  approach.  \\n \\nDATE:  \\nPLACE:  HYDERABAD  P. JYOTHI'),\n",
       " Document(id='8c39247c-d49e-4c3a-b7b0-a35ea3918221', metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"integration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = retriever.invoke(\"What key features in a resume should be prioritized for embedding (e.g., skills, experiences, education)?\")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1864adf4-04a3-4ed4-b332-3f8c884c6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_doc=''\n",
    "for i1 in retrieved_documents:\n",
    "    ret_doc = ret_doc+i1.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4838043-5ce5-48d7-9b9e-230817ad31d5",
   "metadata": {},
   "source": [
    "# Make a prompt and ask question from the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d8805-2cf4-47dc-883a-2200172cb2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',  MySQL,  SQLite.  \\nData Visualization  :  Tableau,  Power  BI,  Excel,  Matplotlib,  Seaborn.  \\n  \\n1) Prathigudupu Jyothi 2) IBM intro into Data Analytics 3) Accenture - Virtual Internship on Data Analytics and Data Visualization'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm.invoke(f\"provide me developer names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422ee93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', SQL Server, MySQL, MongoDB, Tableau.  \\nData  Science  :  Data  Wrangling,  Data  Cleaning,  Data  Manipulation,  Data  Visualization,  Data  Analysis,  Predictive  \\nModeling.  \\n\\n1) FCC, IIT Hyderabad Data Science Workshop Certificate \\n2) Voice Classification Database Certificate \\n3) Decision Tree Classifiers Certificate \\n4) Heart Attack Analysis Certificate \\n5) Hackerank Certification \\n6) Internpe Python Programming Certificate \\n7) IBM Intro into Data Analytics Certificate \\n8) Internshala Web Development Certificate \\n9) Accenture Virtual Internship Certificate \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide me Data Science names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5a75355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', MySQL, SQLite.  \\nWeb  Technologies  : HTML, CSS, Bootstrap.  \\nTools  : Jupyter Notebook, Microsoft Excel, Power BI, Tableau, Git, GitHub.  \\n \\nPROJECTS  \\n \\n1) Voice Classification to identify the voice of male and female based upon acoustic properties of the voice and speech \\nThis database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. \\nThe dataset consists of 3800 recorded voice samples. Using machine learning techniques such as decision trees and \\nsupport vector machines, the model achieved an accuracy of 95%. \\n2) Decision Tree Classifiers Using Bank Dataset to Predict whether a person is eligible for loan amount \\nUtilizing decision tree classifiers, this project aimed to predict whether a person is eligible for a loan based on various \\nfeatures such as income, education, marital status, etc. The model achieved an accuracy of 86%. \\n3) Heart Attack Analysis and Prediction \\nUsing a dataset of 300,000 patients, this project involved analyzing various factors such as age, gender, cholesterol levels, \\netc. to determine the risk of heart attack. The final model achieved an accuracy of 76% and revealed important insights \\ninto factors influencing heart attack. \\n \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide me skills based on these resumes {ret_doc} in Json format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04bd33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm sorry, but I am an AI and do not have access to that information. It is not appropriate to ask for a list of all people.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide me names of all people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c811303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', MongoDB, MySQL.  \\nWeb  Development  : HTML5, CSS3, Bootstrap4 ,  JavaScript,  Node.js ,  Express.js ,  React.js.  \\n \\nCERTIFICATIONS  \\n \\n● Data  Science  Internshala  -  Certified  Data  Science  Professional.  \\n● The  Data  Science  Course  2021:  Complete  Data  Science  Bootcamp  -  Udemy.  \\n● Machine  Learning  A-Z™:  Hands -On  Python  &  R  In  Data  Science  -  Udemy.  \\n● Machine  Learning  -  Coursera  by  Stanford  University.  \\n \\nACHIEVEMENTS  \\n \\n● Secured  2nd  rank  in  Kaggle’s  “Titanic:  Machine  Learning  from  Disaster”  competition  out of  10,000+  participants.  \\n● Completed  the  Accenture  Virtual  Internship  on  Data  Analytics  and  Data  Visualization.  \\n● Selected  as  a  Data  Science  Trainee  at  Internshala  and  successfully  completed  the  training.  \\n● Awarded  a 25'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide me skills based on these resumes {ret_doc} in Json format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36e4df58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n \\nNAMES: \\n1) Jyothi Prathigudupu\\n2) Prathigudupu Jyothi'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide me not career gap people names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50121ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', Excel to MySQL Database, SQLite.  \\nData  Visualization  : Power BI, Tableau, Excel.\\n\\nPossible business analyst names from this text could be:\\n\\n1. Prathigudupu Jyothi\\n2. Jyothi Prathigudupu\\n3. Internpe\\n4. IBM\\n5. Internshala\\n6. Accenture'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide bussiness analyst names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd241562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', MySQL, SQLite.  \\nData  Visualization  : Tableau, Power BI. \\n\\n1) Prathigudupu Jyothi\\n2) IBM intro into Data Analytics - data analytics\\n3) Accenture - Virtual Internship on Data Analytics and Data Visualization'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide analyst names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de2bea70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', SQLite. \\nWeb  Technologies  : HTML, CSS. \\nData  Visualization  : Power BI, Tableau, Excel. \\nDevOps  : Git, GitHub. \\nOther  Tools  : Excel, Microsoft  Word,  Microsoft  PowerPoint. \\nResearch  Skills  : Data  Analysis,  Model  Development,  Feature  Engineering,  Data  Visualization. \\n \\nCERTIFICATIONS  \\n• Hackerank Aug - 2024 \\n• Internpe – Python Programming \\n• IBM intro into Data Analytics – data analytics \\n• Internshala – Web development \\n• Accenture – Virtual Internship on Data Analytics and Data Visualization \\n \\nINTERESTS  \\n• Machine Learning and AI \\n• Data Science and Analytics \\n• Natural Language Processing (NLP) \\n• Predictive Modeling and Forecasting '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(f\"provide machine learning names from this text {ret_doc} in csv format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec4ffc9-da4e-44b0-9914-ca829f23b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what comes next to Sunday? # we are assuiming 1000 words in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc198e15-156e-4d20-8901-139331110547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what =>[0,0,0,0,12,...0,0,0]\n",
    "# come => [0,0,0,0,...0,0,0...23,0,0,0]\n",
    "# next => [0,0,0,34,0,0,0,..0]\n",
    "# to => [0,0,0,0,0,45,0,0,....,0]\n",
    "# sunday => [0,0,0,0,89,...0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb1671f-2181-464b-a1fe-5dec5fe2fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "aiobotocore @ file:///C:/b/abs_3cwz1w13nn/croot/aiobotocore_1701291550158/work\n",
      "aiofiles==23.2.1\n",
      "aiohttp @ file:///C:/b/abs_27h_1rpxgd/croot/aiohttp_1707342354614/work\n",
      "aioitertools @ file:///tmp/build/80754af9/aioitertools_1607109665762/work\n",
      "aiosignal @ file:///tmp/build/80754af9/aiosignal_1637843061372/work\n",
      "alabaster @ file:///home/ktietz/src/ci/alabaster_1611921544520/work\n",
      "alembic==1.13.1\n",
      "altair @ file:///C:/b/abs_27reu1igbg/croot/altair_1687526066495/work\n",
      "anaconda-anon-usage @ file:///C:/b/abs_95v3x0wy8p/croot/anaconda-anon-usage_1697038984188/work\n",
      "anaconda-catalogs @ file:///C:/b/abs_8btyy0o8s8/croot/anaconda-catalogs_1685727315626/work\n",
      "anaconda-client @ file:///C:/b/abs_34txutm0ue/croot/anaconda-client_1708640705294/work\n",
      "anaconda-cloud-auth @ file:///C:/b/abs_410afndtyf/croot/anaconda-cloud-auth_1697462767853/work\n",
      "anaconda-navigator @ file:///C:/b/abs_cfvv8k_j21/croot/anaconda-navigator_1704813334508/work\n",
      "anaconda-project @ file:///C:/ci_311/anaconda-project_1676458365912/work\n",
      "aniso8601==9.0.1\n",
      "annotated-types==0.7.0\n",
      "anyio @ file:///C:/b/abs_847uobe7ea/croot/anyio_1706220224037/work\n",
      "appdirs==1.4.4\n",
      "archspec @ file:///croot/archspec_1697725767277/work\n",
      "argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\n",
      "argon2-cffi-bindings @ file:///C:/ci_311/argon2-cffi-bindings_1676424443321/work\n",
      "arrow @ file:///C:/ci_311/arrow_1678249767083/work\n",
      "astroid @ file:///C:/ci_311/astroid_1678740610167/work\n",
      "astropy @ file:///C:/b/abs_2fb3x_tapx/croot/astropy_1697468987983/work\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\n",
      "astunparse==1.6.3\n",
      "async-lru @ file:///C:/b/abs_e0hjkvwwb5/croot/async-lru_1699554572212/work\n",
      "atomicwrites==1.4.0\n",
      "attrs @ file:///C:/b/abs_35n0jusce8/croot/attrs_1695717880170/work\n",
      "Automat @ file:///tmp/build/80754af9/automat_1600298431173/work\n",
      "autopep8 @ file:///opt/conda/conda-bld/autopep8_1650463822033/work\n",
      "Babel @ file:///C:/ci_311/babel_1676427169844/work\n",
      "backoff==2.2.1\n",
      "backports.functools-lru-cache @ file:///tmp/build/80754af9/backports.functools_lru_cache_1618170165463/work\n",
      "backports.tempfile @ file:///home/linux1/recipes/ci/backports.tempfile_1610991236607/work\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt @ file:///C:/ci_311/bcrypt_1676435170049/work\n",
      "beautifulsoup4==4.12.3\n",
      "binaryornot @ file:///tmp/build/80754af9/binaryornot_1617751525010/work\n",
      "black @ file:///C:/b/abs_29gqa9a44y/croot/black_1701097690150/work\n",
      "bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work\n",
      "blinker @ file:///C:/b/abs_d9y2dm7cw2/croot/blinker_1696539752170/work\n",
      "bokeh @ file:///C:/b/abs_74ungdyhwc/croot/bokeh_1706912192007/work\n",
      "boltons @ file:///C:/ci_311/boltons_1677729932371/work\n",
      "botocore @ file:///C:/b/abs_5a285dtc94/croot/botocore_1701286504141/work\n",
      "Bottleneck @ file:///C:/b/abs_f05kqh7yvj/croot/bottleneck_1707864273291/work\n",
      "Brotli @ file:///C:/ci_311/brotli-split_1676435766766/work\n",
      "bs4==0.0.2\n",
      "cachetools @ file:///tmp/build/80754af9/cachetools_1619597386817/work\n",
      "certifi @ file:///C:/b/abs_35d7n66oz9/croot/certifi_1707229248467/work/certifi\n",
      "cffi @ file:///C:/b/abs_924gv1kxzj/croot/cffi_1700254355075/work\n",
      "chardet @ file:///C:/ci_311/chardet_1676436134885/work\n",
      "charset-normalizer==3.3.2\n",
      "click @ file:///C:/b/abs_f9ihnt72pu/croot/click_1698129847492/work\n",
      "cloudpickle @ file:///C:/b/abs_3796yxesic/croot/cloudpickle_1683040098851/work\n",
      "clyent==1.2.2\n",
      "colorama @ file:///C:/ci_311/colorama_1676422310965/work\n",
      "colorcet @ file:///C:/ci_311/colorcet_1676440389947/work\n",
      "comm @ file:///C:/ci_311/comm_1678376562840/work\n",
      "conda @ file:///C:/b/abs_89vd8hj61u/croot/conda_1708369170790/work\n",
      "conda-build @ file:///C:/b/abs_3ed9gavxgz/croot/conda-build_1708025907525/work\n",
      "conda-content-trust @ file:///C:/b/abs_e3bcpyv7sw/croot/conda-content-trust_1693490654398/work\n",
      "conda-libmamba-solver @ file:///croot/conda-libmamba-solver_1706733287605/work/src\n",
      "conda-pack @ file:///tmp/build/80754af9/conda-pack_1611163042455/work\n",
      "conda-package-handling @ file:///C:/b/abs_b9wp3lr1gn/croot/conda-package-handling_1691008700066/work\n",
      "conda-repo-cli==1.0.75\n",
      "conda-token @ file:///Users/paulyim/miniconda3/envs/c3i/conda-bld/conda-token_1662660369760/work\n",
      "conda-verify==3.4.2\n",
      "conda_index @ file:///croot/conda-index_1706633791028/work\n",
      "conda_package_streaming @ file:///C:/b/abs_6c28n38aaj/croot/conda-package-streaming_1690988019210/work\n",
      "constantly @ file:///C:/b/abs_cbuavw4443/croot/constantly_1703165617403/work\n",
      "contourpy @ file:///C:/b/abs_853rfy8zse/croot/contourpy_1700583617587/work\n",
      "cookiecutter @ file:///C:/b/abs_3d1730toam/croot/cookiecutter_1700677089156/work\n",
      "cryptography @ file:///C:/b/abs_531eqmhgsd/croot/cryptography_1707523768330/work\n",
      "cssselect @ file:///C:/b/abs_71gnjab7b0/croot/cssselect_1707339955530/work\n",
      "cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work\n",
      "cytoolz @ file:///C:/b/abs_d43s8lnb60/croot/cytoolz_1701723636699/work\n",
      "dask @ file:///C:/b/abs_1899k8plyj/croot/dask-core_1701396135885/work\n",
      "dataclasses-json==0.6.7\n",
      "datashader @ file:///C:/b/abs_cb5s63ty8z/croot/datashader_1699544282143/work\n",
      "debugpy @ file:///C:/b/abs_c0y1fjipt2/croot/debugpy_1690906864587/work\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
      "deepdiff==7.0.1\n",
      "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\n",
      "Deprecated==1.2.14\n",
      "diff-match-patch @ file:///Users/ktietz/demo/mc3/conda-bld/diff-match-patch_1630511840874/work\n",
      "dill @ file:///C:/b/abs_084unuus3z/croot/dill_1692271268687/work\n",
      "dirtyjson==1.0.8\n",
      "distributed @ file:///C:/b/abs_5eren88ku4/croot/distributed_1701398076011/work\n",
      "distro @ file:///C:/b/abs_a3uni_yez3/croot/distro_1701455052240/work\n",
      "dnspython==2.6.1\n",
      "docker==7.0.0\n",
      "docstring-to-markdown @ file:///C:/ci_311/docstring-to-markdown_1677742566583/work\n",
      "docutils @ file:///C:/ci_311/docutils_1676428078664/work\n",
      "email_validator==2.2.0\n",
      "emoji==2.12.1\n",
      "entrypoints @ file:///C:/ci_311/entrypoints_1676423328987/work\n",
      "et-xmlfile==1.1.0\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\n",
      "fastapi==0.111.1\n",
      "fastapi-cli==0.0.4\n",
      "fastjsonschema @ file:///C:/ci_311/python-fastjsonschema_1679500568724/work\n",
      "ffmpy==0.3.2\n",
      "filelock @ file:///C:/b/abs_f2gie28u58/croot/filelock_1700591233643/work\n",
      "filetype==1.2.0\n",
      "flake8 @ file:///C:/ci_311/flake8_1678376624746/work\n",
      "Flask @ file:///C:/b/abs_efc024w7fv/croot/flask_1702980041157/work\n",
      "flatbuffers==24.3.25\n",
      "fonttools==4.25.0\n",
      "frozenlist @ file:///C:/b/abs_d8e__s1ys3/croot/frozenlist_1698702612014/work\n",
      "fsspec @ file:///C:/b/abs_97mpfsesn0/croot/fsspec_1701286534629/work\n",
      "future @ file:///C:/ci_311_rebuilds/future_1678998246262/work\n",
      "gast==0.6.0\n",
      "gensim @ file:///C:/ci_311/gensim_1677743037820/work\n",
      "gitdb @ file:///tmp/build/80754af9/gitdb_1617117951232/work\n",
      "GitPython @ file:///C:/b/abs_e1lwow9h41/croot/gitpython_1696937027832/work\n",
      "gmpy2 @ file:///C:/ci_311/gmpy2_1677743390134/work\n",
      "google-api-core==2.19.1\n",
      "google-api-python-client==2.137.0\n",
      "google-auth==2.32.0\n",
      "google-auth-httplib2==0.2.0\n",
      "google-pasta==0.2.0\n",
      "googleapis-common-protos==1.63.2\n",
      "gradio==4.38.1\n",
      "gradio_client==1.1.0\n",
      "graphene==3.3\n",
      "graphql-core==3.2.3\n",
      "graphql-relay==3.2.0\n",
      "greenlet @ file:///C:/b/abs_a6c75ie0bc/croot/greenlet_1702060012174/work\n",
      "grpcio==1.65.4\n",
      "h11==0.14.0\n",
      "h5py==3.11.0\n",
      "HeapDict @ file:///Users/ktietz/demo/mc3/conda-bld/heapdict_1630598515714/work\n",
      "holoviews @ file:///C:/b/abs_704uucojt7/croot/holoviews_1707836477070/work\n",
      "httpcore==1.0.5\n",
      "httplib2==0.22.0\n",
      "httptools==0.6.1\n",
      "httpx==0.27.0\n",
      "huggingface-hub==0.24.0\n",
      "hvplot @ file:///C:/b/abs_3627uzd5h0/croot/hvplot_1706712443782/work\n",
      "hyperlink @ file:///tmp/build/80754af9/hyperlink_1610130746837/work\n",
      "idna @ file:///C:/ci_311/idna_1676424932545/work\n",
      "imagecodecs @ file:///C:/b/abs_e2g5zbs1q0/croot/imagecodecs_1695065012000/work\n",
      "imageio @ file:///C:/b/abs_aeqerw_nps/croot/imageio_1707247365204/work\n",
      "imagesize @ file:///C:/ci_311/imagesize_1676431905616/work\n",
      "imbalanced-learn @ file:///C:/b/abs_87es3kd5fi/croot/imbalanced-learn_1700648276799/work\n",
      "importlib-metadata @ file:///C:/b/abs_c1egths604/croot/importlib_metadata-suite_1704813568388/work\n",
      "importlib_resources==6.4.0\n",
      "incremental @ file:///croot/incremental_1708639938299/work\n",
      "inflection==0.5.1\n",
      "iniconfig @ file:///home/linux1/recipes/ci/iniconfig_1610983019677/work\n",
      "intake @ file:///C:/ci_311_rebuilds/intake_1678999914269/work\n",
      "intervaltree @ file:///Users/ktietz/demo/mc3/conda-bld/intervaltree_1630511889664/work\n",
      "ipykernel @ file:///C:/b/abs_c2u94kxcy6/croot/ipykernel_1705933907920/work\n",
      "ipython @ file:///C:/b/abs_b6pfgmrqnd/croot/ipython_1704833422163/work\n",
      "ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\n",
      "ipywidgets @ file:///croot/ipywidgets_1701289330913/work\n",
      "isort @ file:///tmp/build/80754af9/isort_1628603791788/work\n",
      "itemadapter @ file:///tmp/build/80754af9/itemadapter_1626442940632/work\n",
      "itemloaders @ file:///C:/b/abs_5e3azgv25z/croot/itemloaders_1708639993442/work\n",
      "itsdangerous @ file:///tmp/build/80754af9/itsdangerous_1621432558163/work\n",
      "jaraco.classes @ file:///tmp/build/80754af9/jaraco.classes_1620983179379/work\n",
      "jedi @ file:///C:/ci_311/jedi_1679427407646/work\n",
      "jellyfish @ file:///C:/b/abs_50kgvtnrbj/croot/jellyfish_1695193564091/work\n",
      "Jinja2 @ file:///C:/b/abs_f7x5a8op2h/croot/jinja2_1706733672594/work\n",
      "jiter==0.5.0\n",
      "jmespath @ file:///C:/b/abs_59jpuaows7/croot/jmespath_1700144635019/work\n",
      "joblib @ file:///C:/b/abs_1anqjntpan/croot/joblib_1685113317150/work\n",
      "json5 @ file:///tmp/build/80754af9/json5_1624432770122/work\n",
      "jsonpatch==1.33\n",
      "jsonpath-python==1.0.6\n",
      "jsonpointer==2.1\n",
      "jsonschema @ file:///C:/b/abs_d1c4sm8drk/croot/jsonschema_1699041668863/work\n",
      "jsonschema-specifications @ file:///C:/b/abs_0brvm6vryw/croot/jsonschema-specifications_1699032417323/work\n",
      "jupyter @ file:///C:/b/abs_4e102rc6e5/croot/jupyter_1707947170513/work\n",
      "jupyter-console @ file:///C:/b/abs_82xaa6i2y4/croot/jupyter_console_1680000189372/work\n",
      "jupyter-events @ file:///C:/b/abs_17ajfqnlz0/croot/jupyter_events_1699282519713/work\n",
      "jupyter-lsp @ file:///C:/b/abs_ecle3em9d4/croot/jupyter-lsp-meta_1699978291372/work\n",
      "jupyter_client @ file:///C:/b/abs_a6h3c8hfdq/croot/jupyter_client_1699455939372/work\n",
      "jupyter_core @ file:///C:/b/abs_c769pbqg9b/croot/jupyter_core_1698937367513/work\n",
      "jupyter_server @ file:///C:/b/abs_7esjvdakg9/croot/jupyter_server_1699466495151/work\n",
      "jupyter_server_terminals @ file:///C:/b/abs_ec0dq4b50j/croot/jupyter_server_terminals_1686870763512/work\n",
      "jupyterlab @ file:///C:/b/abs_43venm28fu/croot/jupyterlab_1706802651134/work\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
      "jupyterlab-widgets @ file:///C:/b/abs_adrrqr26no/croot/jupyterlab_widgets_1700169018974/work\n",
      "jupyterlab_server @ file:///C:/b/abs_e08i7qn9m8/croot/jupyterlab_server_1699555481806/work\n",
      "keras==3.4.1\n",
      "keyring @ file:///C:/b/abs_dbjc7g0dh2/croot/keyring_1678999228878/work\n",
      "kiwisolver @ file:///C:/ci_311/kiwisolver_1676431979301/work\n",
      "langchain==0.2.9\n",
      "langchain-community==0.2.7\n",
      "langchain-core==0.3.17\n",
      "langchain-openai==0.2.8\n",
      "langchain-text-splitters==0.2.2\n",
      "langdetect==1.0.9\n",
      "langsmith==0.1.143\n",
      "lazy-object-proxy @ file:///C:/ci_311/lazy-object-proxy_1676432050939/work\n",
      "lazy_loader @ file:///C:/b/abs_3bn4_r4g42/croot/lazy_loader_1695850158046/work\n",
      "lckr_jupyterlab_variableinspector @ file:///C:/b/abs_b5yb2mprx2/croot/jupyterlab-variableinspector_1701096592545/work\n",
      "libarchive-c @ file:///tmp/build/80754af9/python-libarchive-c_1617780486945/work\n",
      "libclang==18.1.1\n",
      "libmambapy @ file:///C:/b/abs_2euls_1a38/croot/mamba-split_1704219444888/work/libmambapy\n",
      "linkify-it-py @ file:///C:/ci_311/linkify-it-py_1676474436187/work\n",
      "llama-cloud==0.0.17\n",
      "llama-index==0.11.9\n",
      "llama-index-agent-openai==0.3.1\n",
      "llama-index-cli==0.3.1\n",
      "llama-index-core==0.11.9\n",
      "llama-index-embeddings-openai==0.2.4\n",
      "llama-index-indices-managed-llama-cloud==0.3.0\n",
      "llama-index-legacy==0.9.48.post3\n",
      "llama-index-llms-openai==0.2.5\n",
      "llama-index-multi-modal-llms-openai==0.2.0\n",
      "llama-index-program-openai==0.2.0\n",
      "llama-index-question-gen-openai==0.2.0\n",
      "llama-index-readers-file==0.2.1\n",
      "llama-index-readers-llama-parse==0.3.0\n",
      "llama-parse==0.5.5\n",
      "llvmlite @ file:///C:/b/abs_da15r8vkf8/croot/llvmlite_1706910779994/work\n",
      "lmdb @ file:///C:/b/abs_556ronuvb2/croot/python-lmdb_1682522366268/work\n",
      "locket @ file:///C:/ci_311/locket_1676428325082/work\n",
      "lxml @ file:///C:/b/abs_9e7tpg2vv9/croot/lxml_1695058219431/work\n",
      "lz4 @ file:///C:/b/abs_064u6aszy3/croot/lz4_1686057967376/work\n",
      "Mako==1.3.5\n",
      "Markdown @ file:///C:/ci_311/markdown_1676437912393/work\n",
      "markdown-it-py @ file:///C:/b/abs_a5bfngz6fu/croot/markdown-it-py_1684279915556/work\n",
      "MarkupSafe @ file:///C:/b/abs_ecfdqh67b_/croot/markupsafe_1704206030535/work\n",
      "marshmallow==3.21.3\n",
      "matplotlib @ file:///C:/b/abs_e26vnvd5s1/croot/matplotlib-suite_1698692153288/work\n",
      "matplotlib-inline @ file:///C:/ci_311/matplotlib-inline_1676425798036/work\n",
      "mccabe @ file:///opt/conda/conda-bld/mccabe_1644221741721/work\n",
      "mdit-py-plugins @ file:///C:/ci_311/mdit-py-plugins_1676481827414/work\n",
      "mdurl @ file:///C:/ci_311/mdurl_1676442676678/work\n",
      "menuinst @ file:///C:/b/abs_099kybla52/croot/menuinst_1706732987063/work\n",
      "mistune @ file:///C:/ci_311/mistune_1676425111783/work\n",
      "mkl-fft @ file:///C:/b/abs_19i1y8ykas/croot/mkl_fft_1695058226480/work\n",
      "mkl-random @ file:///C:/b/abs_edwkj1_o69/croot/mkl_random_1695059866750/work\n",
      "mkl-service==2.4.0\n",
      "ml-dtypes==0.4.0\n",
      "mlflow==2.12.2\n",
      "more-itertools @ file:///C:/b/abs_36p38zj5jx/croot/more-itertools_1700662194485/work\n",
      "mpmath @ file:///C:/b/abs_7833jrbiox/croot/mpmath_1690848321154/work\n",
      "msgpack @ file:///C:/ci_311/msgpack-python_1676427482892/work\n",
      "multidict @ file:///C:/b/abs_44ido987fv/croot/multidict_1701097803486/work\n",
      "multipledispatch @ file:///C:/ci_311/multipledispatch_1676442767760/work\n",
      "munkres==1.1.4\n",
      "mypy @ file:///C:/b/abs_3880czibje/croot/mypy-split_1708366584048/work\n",
      "mypy-extensions @ file:///C:/b/abs_8f7xiidjya/croot/mypy_extensions_1695131051147/work\n",
      "namex==0.0.8\n",
      "navigator-updater @ file:///C:/b/abs_895otdwmo9/croot/navigator-updater_1695210220239/work\n",
      "nbclient @ file:///C:/b/abs_cal0q5fyju/croot/nbclient_1698934263135/work\n",
      "nbconvert @ file:///C:/b/abs_17p29f_rx4/croot/nbconvert_1699022793097/work\n",
      "nbformat @ file:///C:/b/abs_5a2nea1iu2/croot/nbformat_1694616866197/work\n",
      "nest-asyncio @ file:///C:/b/abs_65d6lblmoi/croot/nest-asyncio_1708532721305/work\n",
      "networkx @ file:///C:/b/abs_e6gi1go5op/croot/networkx_1690562046966/work\n",
      "nltk==3.9.1\n",
      "notebook @ file:///C:/b/abs_65xjlnf9q4/croot/notebook_1708029957105/work\n",
      "notebook_shim @ file:///C:/b/abs_a5xysln3lb/croot/notebook-shim_1699455926920/work\n",
      "numba @ file:///C:/b/abs_3e3co1qfvo/croot/numba_1707085143481/work\n",
      "numexpr @ file:///C:/b/abs_5fucrty5dc/croot/numexpr_1696515448831/work\n",
      "numpy @ file:///C:/b/abs_c1ywpu18ar/croot/numpy_and_numpy_base_1708638681471/work/dist/numpy-1.26.4-cp311-cp311-win_amd64.whl#sha256=5dfd3e04dc1c2826d3f404fdc7f93c097901f5da9b91f4f394f79d4e038ed81d\n",
      "numpydoc @ file:///C:/ci_311/numpydoc_1676453412027/work\n",
      "openai==1.54.0\n",
      "openpyxl==3.0.10\n",
      "opt-einsum==3.3.0\n",
      "optree==0.12.1\n",
      "ordered-set==4.1.0\n",
      "orjson==3.10.6\n",
      "overrides @ file:///C:/b/abs_cfh89c8yf4/croot/overrides_1699371165349/work\n",
      "packaging==24.1\n",
      "pandas @ file:///C:/b/abs_fej9bi0gew/croot/pandas_1702318041921/work/dist/pandas-2.1.4-cp311-cp311-win_amd64.whl#sha256=d3609b7cc3e3c4d99ad640a4b8e710ba93ccf967ab8e5245b91033e0200f9286\n",
      "pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work\n",
      "panel @ file:///C:/b/abs_abnm_ot327/croot/panel_1706539613212/work\n",
      "param @ file:///C:/b/abs_39ncjvb7lu/croot/param_1705937833389/work\n",
      "paramiko @ file:///opt/conda/conda-bld/paramiko_1640109032755/work\n",
      "parsel @ file:///C:/b/abs_ebc3tzm_c4/croot/parsel_1707503517596/work\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\n",
      "partd @ file:///C:/b/abs_46awex0fd7/croot/partd_1698702622970/work\n",
      "pathlib @ file:///Users/ktietz/demo/mc3/conda-bld/pathlib_1629713961906/work\n",
      "pathspec @ file:///C:/ci_311/pathspec_1679427644142/work\n",
      "patsy==0.5.3\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\n",
      "pillow @ file:///C:/b/abs_e22m71t0cb/croot/pillow_1707233126420/work\n",
      "pkce @ file:///C:/b/abs_d0z4444tb0/croot/pkce_1690384879799/work\n",
      "pkginfo @ file:///C:/b/abs_d18srtr68x/croot/pkginfo_1679431192239/work\n",
      "platformdirs @ file:///C:/b/abs_b6z_yqw_ii/croot/platformdirs_1692205479426/work\n",
      "plotly @ file:///C:/ci_311/plotly_1676443558683/work\n",
      "pluggy @ file:///C:/ci_311/pluggy_1676422178143/work\n",
      "ply==3.11\n",
      "prometheus-client @ file:///C:/ci_311/prometheus_client_1679591942558/work\n",
      "prompt-toolkit @ file:///C:/b/abs_68uwr58ed1/croot/prompt-toolkit_1704404394082/work\n",
      "Protego @ file:///tmp/build/80754af9/protego_1598657180827/work\n",
      "proto-plus==1.24.0\n",
      "protobuf==3.20.3\n",
      "psutil @ file:///C:/ci_311_rebuilds/psutil_1679005906571/work\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\n",
      "py-cpuinfo @ file:///C:/b/abs_9ej7u6shci/croot/py-cpuinfo_1698068121579/work\n",
      "pyarrow @ file:///C:/b/abs_93i_y2dub4/croot/pyarrow_1707330894046/work/python\n",
      "pyasn1 @ file:///Users/ktietz/demo/mc3/conda-bld/pyasn1_1629708007385/work\n",
      "pyasn1-modules==0.2.8\n",
      "pycodestyle @ file:///C:/ci_311/pycodestyle_1678376707834/work\n",
      "pycosat @ file:///C:/b/abs_31zywn1be3/croot/pycosat_1696537126223/work\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\n",
      "pyct @ file:///C:/ci_311/pyct_1676438538057/work\n",
      "pycurl==7.45.2\n",
      "pydantic==2.8.2\n",
      "pydantic_core==2.20.1\n",
      "pydeck @ file:///C:/b/abs_ad9p880wi1/croot/pydeck_1706194121328/work\n",
      "PyDispatcher==2.0.5\n",
      "pydocstyle @ file:///C:/ci_311/pydocstyle_1678402028085/work\n",
      "pydub==0.25.1\n",
      "pyerfa @ file:///C:/ci_311/pyerfa_1676503994641/work\n",
      "pyflakes @ file:///C:/ci_311/pyflakes_1678402101687/work\n",
      "Pygments @ file:///C:/b/abs_fay9dpq4n_/croot/pygments_1684279990574/work\n",
      "PyJWT @ file:///C:/ci_311/pyjwt_1676438890509/work\n",
      "pylint @ file:///C:/ci_311/pylint_1678740302984/work\n",
      "pylint-venv @ file:///C:/ci_311/pylint-venv_1678402170638/work\n",
      "pyls-spyder==0.4.0\n",
      "pymongo==4.7.3\n",
      "PyMySQL==1.1.1\n",
      "PyNaCl @ file:///C:/ci_311/pynacl_1676445861112/work\n",
      "pyodbc @ file:///C:/b/abs_90kly0uuwz/croot/pyodbc_1705431396548/work\n",
      "pyOpenSSL @ file:///C:/b/abs_baj0aupznq/croot/pyopenssl_1708380486701/work\n",
      "pyparsing @ file:///C:/ci_311/pyparsing_1678502182533/work\n",
      "pypdf==4.3.0\n",
      "PyQt5==5.15.10\n",
      "PyQt5-sip @ file:///C:/b/abs_c0pi2mimq3/croot/pyqt-split_1698769125270/work/pyqt_sip\n",
      "PyQtWebEngine==5.15.6\n",
      "PySocks @ file:///C:/ci_311/pysocks_1676425991111/work\n",
      "pytest @ file:///C:/b/abs_48heoo_k8y/croot/pytest_1690475385915/work\n",
      "python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\n",
      "python-dotenv @ file:///C:/ci_311/python-dotenv_1676455170580/work\n",
      "python-iso639==2024.4.27\n",
      "python-json-logger @ file:///C:/b/abs_cblnsm6puj/croot/python-json-logger_1683824130469/work\n",
      "python-lsp-black @ file:///C:/ci_311/python-lsp-black_1678721855627/work\n",
      "python-lsp-jsonrpc==1.0.0\n",
      "python-lsp-server @ file:///C:/b/abs_catecj7fv1/croot/python-lsp-server_1681930405912/work\n",
      "python-magic==0.4.27\n",
      "python-multipart==0.0.9\n",
      "python-slugify @ file:///tmp/build/80754af9/python-slugify_1620405669636/work\n",
      "python-snappy @ file:///C:/ci_311/python-snappy_1676446060182/work\n",
      "pytoolconfig @ file:///C:/b/abs_f2j_xsvrpn/croot/pytoolconfig_1701728751207/work\n",
      "pytz @ file:///C:/b/abs_19q3ljkez4/croot/pytz_1695131651401/work\n",
      "pyviz_comms @ file:///C:/b/abs_31r9afnand/croot/pyviz_comms_1701728067143/work\n",
      "pywavelets @ file:///C:/b/abs_7est386xsb/croot/pywavelets_1705049855879/work\n",
      "pywin32==305.1\n",
      "pywin32-ctypes @ file:///C:/ci_311/pywin32-ctypes_1676427747089/work\n",
      "pywinpty @ file:///C:/ci_311/pywinpty_1677707791185/work/target/wheels/pywinpty-2.0.10-cp311-none-win_amd64.whl\n",
      "PyYAML @ file:///C:/b/abs_782o3mbw7z/croot/pyyaml_1698096085010/work\n",
      "pyzmq @ file:///C:/b/abs_89aq69t0up/croot/pyzmq_1705605705281/work\n",
      "QDarkStyle @ file:///tmp/build/80754af9/qdarkstyle_1617386714626/work\n",
      "qstylizer @ file:///C:/ci_311/qstylizer_1678502012152/work/dist/qstylizer-0.2.2-py2.py3-none-any.whl\n",
      "QtAwesome @ file:///C:/ci_311/qtawesome_1678402331535/work\n",
      "qtconsole @ file:///C:/b/abs_eb4u9jg07y/croot/qtconsole_1681402843494/work\n",
      "QtPy @ file:///C:/b/abs_derqu__3p8/croot/qtpy_1700144907661/work\n",
      "querystring-parser==1.2.4\n",
      "queuelib @ file:///C:/b/abs_563lpxcne9/croot/queuelib_1696951148213/work\n",
      "rapidfuzz==3.9.4\n",
      "referencing @ file:///C:/b/abs_09f4hj6adf/croot/referencing_1699012097448/work\n",
      "regex @ file:///C:/b/abs_d5e2e5uqmr/croot/regex_1696515472506/work\n",
      "requests @ file:///C:/b/abs_474vaa3x9e/croot/requests_1707355619957/work\n",
      "requests-file @ file:///Users/ktietz/demo/mc3/conda-bld/requests-file_1629455781986/work\n",
      "requests-toolbelt @ file:///C:/b/abs_2fsmts66wp/croot/requests-toolbelt_1690874051210/work\n",
      "rfc3339-validator @ file:///C:/b/abs_ddfmseb_vm/croot/rfc3339-validator_1683077054906/work\n",
      "rfc3986-validator @ file:///C:/b/abs_6e9azihr8o/croot/rfc3986-validator_1683059049737/work\n",
      "rich @ file:///C:/b/abs_09j2g5qnu8/croot/rich_1684282185530/work\n",
      "rope @ file:///C:/ci_311/rope_1678402524346/work\n",
      "rpds-py @ file:///C:/b/abs_76j4g4la23/croot/rpds-py_1698947348047/work\n",
      "rsa==4.9\n",
      "Rtree @ file:///C:/ci_311/rtree_1676455758391/work\n",
      "ruamel-yaml-conda @ file:///C:/ci_311/ruamel_yaml_1676455799258/work\n",
      "ruamel.yaml @ file:///C:/ci_311/ruamel.yaml_1676439214109/work\n",
      "ruff==0.5.2\n",
      "s3fs @ file:///C:/b/abs_24vbfcawyu/croot/s3fs_1701294224436/work\n",
      "scikit-image @ file:///C:/b/abs_f7z1pjjn6f/croot/scikit-image_1707346180040/work\n",
      "scikit-learn @ file:///C:/b/abs_38k7ridbgr/croot/scikit-learn_1684954723009/work\n",
      "scipy==1.11.4\n",
      "Scrapy @ file:///C:/ci_311/scrapy_1678502587780/work\n",
      "seaborn @ file:///C:/ci_311/seaborn_1676446547861/work\n",
      "semantic-version==2.10.0\n",
      "semver @ file:///tmp/build/80754af9/semver_1603822362442/work\n",
      "Send2Trash @ file:///C:/b/abs_08dh49ew26/croot/send2trash_1699371173324/work\n",
      "service-identity @ file:///Users/ktietz/demo/mc3/conda-bld/service_identity_1629460757137/work\n",
      "shellingham==1.5.4\n",
      "sip @ file:///C:/b/abs_edevan3fce/croot/sip_1698675983372/work\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
      "smart-open @ file:///C:/ci_311/smart_open_1676439339434/work\n",
      "smmap @ file:///tmp/build/80754af9/smmap_1611694433573/work\n",
      "sniffio @ file:///C:/b/abs_3akdewudo_/croot/sniffio_1705431337396/work\n",
      "snowballstemmer @ file:///tmp/build/80754af9/snowballstemmer_1637937080595/work\n",
      "sortedcontainers @ file:///tmp/build/80754af9/sortedcontainers_1623949099177/work\n",
      "soupsieve @ file:///C:/b/abs_bbsvy9t4pl/croot/soupsieve_1696347611357/work\n",
      "Sphinx @ file:///C:/ci_311/sphinx_1676434546244/work\n",
      "sphinxcontrib-applehelp @ file:///home/ktietz/src/ci/sphinxcontrib-applehelp_1611920841464/work\n",
      "sphinxcontrib-devhelp @ file:///home/ktietz/src/ci/sphinxcontrib-devhelp_1611920923094/work\n",
      "sphinxcontrib-htmlhelp @ file:///tmp/build/80754af9/sphinxcontrib-htmlhelp_1623945626792/work\n",
      "sphinxcontrib-jsmath @ file:///home/ktietz/src/ci/sphinxcontrib-jsmath_1611920942228/work\n",
      "sphinxcontrib-qthelp @ file:///home/ktietz/src/ci/sphinxcontrib-qthelp_1611921055322/work\n",
      "sphinxcontrib-serializinghtml @ file:///tmp/build/80754af9/sphinxcontrib-serializinghtml_1624451540180/work\n",
      "spyder @ file:///C:/b/abs_e99kl7d8t0/croot/spyder_1681934304813/work\n",
      "spyder-kernels @ file:///C:/b/abs_e788a8_4y9/croot/spyder-kernels_1691599588437/work\n",
      "SQLAlchemy @ file:///C:/b/abs_876dxwqqu8/croot/sqlalchemy_1705089154696/work\n",
      "sqlparse==0.5.0\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\n",
      "starlette==0.37.2\n",
      "statsmodels @ file:///C:/b/abs_7bth810rna/croot/statsmodels_1689937298619/work\n",
      "streamlit @ file:///C:/b/abs_ba5je7xxy7/croot/streamlit_1706200559831/work\n",
      "striprtf==0.0.26\n",
      "sympy @ file:///C:/b/abs_82njkonm7f/croot/sympy_1701397685028/work\n",
      "tables @ file:///C:/b/abs_411740ajo7/croot/pytables_1705614883108/work\n",
      "tabulate @ file:///C:/b/abs_21rf8iibnh/croot/tabulate_1701354830521/work\n",
      "tblib @ file:///Users/ktietz/demo/mc3/conda-bld/tblib_1629402031467/work\n",
      "tenacity @ file:///C:/b/abs_ddkoa9nju6/croot/tenacity_1682972298929/work\n",
      "tensorboard==2.17.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.17.0\n",
      "tensorflow-intel==2.17.0\n",
      "tensorflow-io-gcs-filesystem==0.31.0\n",
      "termcolor==2.4.0\n",
      "terminado @ file:///C:/ci_311/terminado_1678228513830/work\n",
      "text-unidecode @ file:///Users/ktietz/demo/mc3/conda-bld/text-unidecode_1629401354553/work\n",
      "textdistance @ file:///tmp/build/80754af9/textdistance_1612461398012/work\n",
      "threadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\n",
      "three-merge @ file:///tmp/build/80754af9/three-merge_1607553261110/work\n",
      "tifffile @ file:///C:/b/abs_45o5chuqwt/croot/tifffile_1695107511025/work\n",
      "tiktoken==0.7.0\n",
      "tinycss2 @ file:///C:/ci_311/tinycss2_1676425376744/work\n",
      "tldextract @ file:///opt/conda/conda-bld/tldextract_1646638314385/work\n",
      "toml @ file:///tmp/build/80754af9/toml_1616166611790/work\n",
      "tomlkit==0.12.0\n",
      "toolz @ file:///C:/ci_311/toolz_1676431406517/work\n",
      "torch==2.2.2+cpu\n",
      "torchaudio==2.2.2+cpu\n",
      "torchvision==0.17.2+cpu\n",
      "tornado @ file:///C:/b/abs_0cbrstidzg/croot/tornado_1696937003724/work\n",
      "tqdm==4.66.5\n",
      "traitlets @ file:///C:/ci_311/traitlets_1676423290727/work\n",
      "truststore @ file:///C:/b/abs_55z7b3r045/croot/truststore_1695245455435/work\n",
      "Twisted @ file:///C:/b/abs_e7yqd811in/croot/twisted_1708702883769/work\n",
      "twisted-iocpsupport @ file:///C:/ci_311/twisted-iocpsupport_1676447612160/work\n",
      "typer==0.12.3\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata @ file:///croot/python-tzdata_1690578112552/work\n",
      "tzlocal @ file:///C:/ci_311/tzlocal_1676439620276/work\n",
      "uc-micro-py @ file:///C:/ci_311/uc-micro-py_1676457695423/work\n",
      "ujson @ file:///C:/ci_311/ujson_1676434714224/work\n",
      "Unidecode @ file:///tmp/build/80754af9/unidecode_1614712377438/work\n",
      "unstructured==0.14.10\n",
      "unstructured-client==0.24.1\n",
      "uritemplate==4.1.1\n",
      "urllib3 @ file:///C:/b/abs_0c3739ssy1/croot/urllib3_1707349314852/work\n",
      "uvicorn==0.30.1\n",
      "validators @ file:///tmp/build/80754af9/validators_1612286467315/work\n",
      "w3lib @ file:///C:/b/abs_957begrwnl/croot/w3lib_1708640020760/work\n",
      "waitress==3.0.0\n",
      "watchdog @ file:///C:/ci_311/watchdog_1676457923624/work\n",
      "watchfiles==0.22.0\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
      "webencodings==0.5.1\n",
      "websocket-client @ file:///C:/ci_311/websocket-client_1676426063281/work\n",
      "websockets==11.0.3\n",
      "Werkzeug @ file:///C:/b/abs_8578rs2ra_/croot/werkzeug_1679489759009/work\n",
      "whatthepatch @ file:///C:/ci_311/whatthepatch_1678402578113/work\n",
      "widgetsnbextension @ file:///C:/b/abs_derxhz1biv/croot/widgetsnbextension_1701273671518/work\n",
      "win-inet-pton @ file:///C:/ci_311/win_inet_pton_1676425458225/work\n",
      "wrapt @ file:///C:/ci_311/wrapt_1676432805090/work\n",
      "xarray @ file:///C:/b/abs_5bkjiynp4e/croot/xarray_1689041498548/work\n",
      "xlwings @ file:///C:/ci_311_rebuilds/xlwings_1679013429160/work\n",
      "xyzservices @ file:///C:/ci_311/xyzservices_1676434829315/work\n",
      "yapf @ file:///tmp/build/80754af9/yapf_1615749224965/work\n",
      "yarl @ file:///C:/b/abs_8bxwdyhjvp/croot/yarl_1701105248152/work\n",
      "youtube-transcript-api==0.6.2\n",
      "zict @ file:///C:/b/abs_780gyydtbp/croot/zict_1695832899404/work\n",
      "zipp @ file:///C:/b/abs_b0beoc27oa/croot/zipp_1704206963359/work\n",
      "zope.interface @ file:///C:/ci_311/zope.interface_1676439868776/work\n",
      "zstandard==0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5194ebc8-a73b-4157-a30f-5843b61d6fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.3.7)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pydantic in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.9.0)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.54.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.3.17)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain) (8.5.0)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic) (2024.1)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.5.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nr802\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Downloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Downloading torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 6.0/203.1 MB 30.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 10.0/203.1 MB 28.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 13.4/203.1 MB 24.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 18.1/203.1 MB 21.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 22.0/203.1 MB 21.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 25.4/203.1 MB 20.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 30.1/203.1 MB 20.3 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 34.6/203.1 MB 20.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 38.0/203.1 MB 20.7 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 40.9/203.1 MB 19.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 43.3/203.1 MB 18.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 46.4/203.1 MB 18.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.5/203.1 MB 17.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 51.9/203.1 MB 17.8 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 55.3/203.1 MB 17.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 57.7/203.1 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 62.1/203.1 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 67.1/203.1 MB 17.5 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 69.5/203.1 MB 17.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.1/203.1 MB 17.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.6/203.1 MB 17.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.4/203.1 MB 17.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 81.5/203.1 MB 16.8 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 85.7/203.1 MB 16.9 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 88.1/203.1 MB 16.6 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 88.3/203.1 MB 16.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 91.8/203.1 MB 16.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 96.7/203.1 MB 16.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 99.1/203.1 MB 16.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 102.2/203.1 MB 16.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 104.3/203.1 MB 16.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 106.4/203.1 MB 15.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 108.8/203.1 MB 15.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 111.4/203.1 MB 15.5 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 112.7/203.1 MB 15.3 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.8/203.1 MB 15.0 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 114.0/203.1 MB 14.9 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 115.9/203.1 MB 14.5 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 118.0/203.1 MB 14.3 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 119.5/203.1 MB 14.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 119.8/203.1 MB 13.9 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 121.9/203.1 MB 13.7 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 123.5/203.1 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 124.3/203.1 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 126.6/203.1 MB 13.3 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.2/203.1 MB 13.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 129.2/203.1 MB 13.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 132.6/203.1 MB 13.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 133.4/203.1 MB 13.0 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.2/203.1 MB 12.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 136.3/203.1 MB 12.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 138.1/203.1 MB 12.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 139.2/203.1 MB 12.5 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 141.3/203.1 MB 12.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 143.7/203.1 MB 12.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 144.4/203.1 MB 12.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 146.0/203.1 MB 12.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 146.8/203.1 MB 12.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 148.1/203.1 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.7/203.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 150.5/203.1 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 151.0/203.1 MB 11.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.8/203.1 MB 11.5 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 153.9/203.1 MB 11.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 156.8/203.1 MB 11.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 159.1/203.1 MB 11.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 160.7/203.1 MB 11.3 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.5/203.1 MB 11.3 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.4/203.1 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 167.2/203.1 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 169.9/203.1 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 172.5/203.1 MB 11.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.8/203.1 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 175.4/203.1 MB 11.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.0/203.1 MB 11.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.8/203.1 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 179.8/203.1 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 182.2/203.1 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.5/203.1 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.0/203.1 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.9/203.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.6/203.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.9/203.1 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 187.2/203.1 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 187.7/203.1 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 189.0/203.1 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.1/203.1 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 192.7/203.1 MB 10.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 194.2/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.1/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.3/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.6/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.1/203.1 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/10.0 MB 8.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/10.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.1/10.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/10.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, safetensors, python-multipart, filelock, uvicorn, torch, starlette, huggingface-hub, tokenizers, fastapi, transformers, sentence-transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nr802\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\transformers\\\\models\\\\deprecated\\\\trajectory_transformer\\\\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain fastapi uvicorn pydantic python-multipart sentence-transformers openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8437da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 0}, page_content='NAGASRI BHAG YAV ALLI KURMALA  \\nPhone  : +91 9849824437       Email : bhagyakhannakurmala @gmail.com  \\nAddress  : HYDERABAD - 500018  \\n  \\nCAREER OBJECTIVE:    \\nSeeking a data scientist role at an innovative firm valuing analytics, coding, and passion for data. Eager to tackle big \\nprojects with the latest tech and enhance skills in stats, machine learning, and data visualization. Ready to collaborate, \\naddress chal lenges, and drive data -informed decisions, with a commitment to continuous learning.  \\n  \\nEDUCATION:   \\nAditya Degree College , Eluru 2021 - 2024 \\nBachelor of Computer Aplications -89%   \\nAditya Junior Colle ge, Eluru  2019 - 2021  \\nIntermediate – 94%   \\n   Sri Chaitanya Techno School  \\nSSC -10 CGPA     \\n2017- 2018 \\nTECHNICAL SKILLS :   \\n• Python  : Functions and Modules , Data Structures   \\n• OOPs  : Inheritance, Polymorphism, Encapsulation, Object, Class, Abstraction.  \\n• Machine Learning  : EDA , Linear Regression, Logistic Regression, Decision Tree, SVM, XGBoost,  \\nAdaBoost, Random Forest Algorithms , NLP.  \\n• SQL  \\n• Power B i  : Data Types, Functions, Joins and Subqueries, Indexes  \\n \\n \\n SOFT SKILLS:    \\n• Analytical Thinking   \\n• Problem Solving  \\n• Effective Communication  \\n• Team Collaboration  \\n• Known Languages: English, Telugu, and Hindi  \\n    \\n \\n \\nLIBRARY MANAGEMENT SYSTEM USING RFID:  \\nThis Libraries are very important aspects for humans. They are essential in acquiring and retaining the knowledge of a \\nperson. But the earlier library system has caused many problems. This project helps to identify the large number of \\ntagged books using ra dio waves. The database shows the availability of the book in the library so that the student can \\nsearch in the database and if available, they can collect book from the library. It helps to handle the issue, renewal and \\nreturn process via RFID tags easily . Student will get notified about the due date of book using GSM. If the student failed \\nto return the book after the due date corresponding fine will be generated based on the time Period. RFID system is used \\nfor theft detection at the library  \\n PROJECTS : \\n '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Bhagyavalli Kurmala QT.pdf', 'page': 1}, page_content=' \\nSMART CONTROL OF TRAFFIC LIGHT USING AI : \\nIt is an Al based project utilizes the YOLO algorithm for real -time vehicle detection and clustering techniques to optimize \\ntraffic light timings based on traffic density.  The system dynamically adjusts signal durations to reduce congestion and \\nimprove traffic flow at intersections.  This Al -driven solution provides an efficient, scalable method for  managing urban \\ntraffic by adapting to real -time conditions and optimizing  resource  usage.  \\n \\n \\n \\n• Cybersecurity certification from CISCO.   \\n• LSRW certification from Mepro  \\n• Machine Learning using Python certification from Verzeo  \\n \\nKKLMM  \\n   \\n• BUSINESS DEVELOPMENT EXECUTIVE internship from “Yoursthatsenior”   \\n• HUMAN RESOURCE internship from “Yoursthatsenior”   \\n• CYBER SECURITY  internship from “ST7 surveillance solution”   \\n• DATA SCIENCE WITH AI  internship from “Quality Thought ”  \\n \\n \\n \\n            I am here to declare that all the information furnished about me is true to the best of my knowledge . \\n   \\n                                                                                                                                                            Bhagyavalli Kurmala  \\n                                                                                                                                                            Hyderabad  \\n CERTIFICATIONS  \\n \\nINTER NSHIPS  \\n \\nDeclarati on '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Kartik_Resume.pdf', 'page': 0}, page_content='KARTIK  PURI  \\npurikartik9742@gmail.com|  +91-9742963481  | Bangalore,  India  | www.linkedin.com/in/kartik -p-30906a218  \\nAs a self -motivated and  hardworking individual with 11 months of experience, I thrive on the challenge of translating \\nbusiness needs into technical solutions. I’m passionate about taking ownership of projects, seeing them through from \\nconcept to launch, and constantly learning a long the way.  \\n     Skills:  \\nCore Competences:  \\nDocker  \\nOpenCV  \\n   \\n  Programming  Languages:   \\n  Python                        : Pandas, NumPy, Matplotlib  \\n  OOPs                         : Inheritance, Polymorphism, Encapsulation, Object, Class, Abstraction.  \\n  Machine Learning     : Linear Regression, Logistic Regression, Decision Tree, SVM, XGBoost, AdaBoost, Random  Forest       \\n  Deep Learning           : CNNs, Natural Language Process  \\n  SQL                           : Data Types, Functions, Joins  \\n \\nCertifications:  \\nProgramming  with Python, Understanding  Incubation  and Entrepreneurship  (NPTEL),  PHP (National  Skill Training \\nInstitute), Data Science for Engineers.  \\nExperiences:  \\nDeepceptAI  Pvt. Ltd.,  Bangalore,  India  Nov 2023  – May  2024  \\nIntern  \\n \\nProjects :   \\n \\nPredictive Modeling with XGBoost and Logistic Regression  \\nThe implementation of predictive models using Logistic Regression and XGBoost classifiers. It includes data \\npreprocessing steps, model training, evaluation using metrics such as R², mean squared e rror, accuracy, and ROC AUC \\nscore. The notebook applies these models to binary classification tasks, compares their performance, and outputs \\npredictions . \\n \\nReal-time Ambulance  Detection  with the YOLOv7  COCO  Model . \\nThis project utilizes the YOLOv7 model trained on the COCO dataset for real -time ambulance detection in video streams. \\nWhen an ambulance is detected, a 10 -second video clip is automatically captured and sent to a designated Telegram bot, \\nenabling immediate  alert notifications. This system enhances emergency response efficiency by providing instant, real -time \\nsituational awareness.  \\n \\nKnife(object)  detection  using  Mobilenet_v2  in Tensorflow . \\nThis project leverages the lightweight and efficient MobileNet_v2 mod el in TensorFlow for real -time detection of knives in \\nvideo feeds or images. The system identifies potentially dangerous objects with high accuracy, making it ideal for \\nenhancing security in public areas or monitoring systems. Its low -latency performance a llows for seamless integration into \\nreal-time surveillance systems . \\n \\nCorizo, Noida,  Uttar  Pradesh,  India  Sep 2022  – Nov 2022  \\nIntern  \\n \\nProjects :  \\n  \\nPerformed  SQL  Injection  in application  using  manual  and automated  tools.  \\nIn this project, SQL injection techniques were employed to exploit vulnerabilities in a web application. Both manual \\nmethods and automated tools, like SQLmap, were used to identify and execute malicious queries, gaining unauthorized \\naccess to sensitive dat a. The project demonstrates how attackers exploit SQL flaws and highlights the importance of \\nsecuring applications against such threats.  \\n \\nPerformed  OS Command  Injection  in application  and extend  the attack  to gain web shell access.  \\nThis project focuses on performing OS Command Injection attacks on a vulnerable application, executing system -level \\ncommands remotely. The attack is further escalated by gaining web shell access, allowing full control over the target server.  '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Kartik_Resume.pdf', 'page': 1}, page_content='This demonstra tes how attackers can exploit command injection vulnerabilities to breach system security, highlighting the \\ncritical need for secure coding  practices and input validation.  \\nEducation:  \\nP.D.A.  College  of Engineering , Kalaburagi,  India  Aug 2023  \\nBachelor  of Engineering  in Computer  Science  Engineering  \\nCoursework:  Internet  of Things,  Machine  Learning,  Computer  Networks,  Web  Application  Security  \\nOrganisation/Activities : Secured  second  place  in Carrom,  Organised  Gaming  Event  in College Fest \\n \\nSundari Anand  Alva Memorial PU College , Moodbidri, India           July 2019  \\nPre-University  '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\KRISHNA CHAITANY RESUME 1.pdf', 'page': 0}, page_content=' \\nGADDAM KRISHNA CHAITANYA \\nMSc. CHEMISTRY \\n \\nAddress : 15-4-163/1, 1st floor, Bhagat Nivas, \\nGowliguda Chaman, Osman Shahi, Hyderabad, Telangana, INDIA – 500012. \\nEmail: gkrishnac20000@gmail.com  \\nMobile No : 6305880569 \\n \\nProfile: \\nA Post graduate student who is passionate about learning and seeking \\ncorporate experience to apply the skills learned through educational knowledge \\nand to improvise the skills into expertise goals. Hard-working, multi-tasking, \\ngood communication skills, and ability to perform well in team environments. \\n \\nEducation : \\n\\uf0d8 Master of Science (MSc) – Chemistry (Drugs and Pharmaceuticals) – \\n 9.31 SGPA. \\nJNTUH – UCESTH, Kukatpally, Hyderabad - 2024. \\n \\n\\uf0d8 Bachelor of Science (BSc) – Biotechnology, Microbiology, Chemistry – \\n 9.0 SGPA, \\nAvanthi Degree & P.G College, Himayathnagar, Hyderabad – 2022. \\n \\n\\uf0d8 Board of Intermediate – Bi.P.C – 91.2 SGPA \\nSri Chaitanya Junior Kalasala, Narayanguda, Hyderabad, - 2017. \\n \\n\\uf0d8 SSC – 92 SGPA \\nShri Gujarati Vidya Mandir High School, Sultan Bazar, Hyderabad – \\n2015 \\n \\nProjects  & Professional Training: \\n\\uf0b7 3rd Semester’s Project (JNTUH - UCESTH)                     \\n   (02/2024 – 03/2024) \\n“Synthesis of N-(1-thiophen-2-yl) ethylidene) pyridine-2-amine” \\n \\n\\uf0b7 4th Semester’s Project (Alkali Metals, Uppal Industrial Area)                      \\n   (05/2024 – 07/2024) \\n“Synthesis of 4-Amino Pyridine” \\n\\uf0b7 Data Science with Generative AI (Quality Thought Infosystems India (P) \\nLtd) \\n(06/2024 – Till date) \\n \\n '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\KRISHNA CHAITANY RESUME 1.pdf', 'page': 1}, page_content=' \\n \\nSkills Acquired : \\n Tools Known: \\n\\uf0b7 Microsoft Office Suite (Word, Excel, PowerPoint) \\n\\uf0b7 Chemdraw \\n\\uf0b7 Python Programming Language. \\n\\uf0b7 Python Libraries \\n\\uf0b7 Machine Learning \\n\\uf0b7 SQL (Structured Query Language) \\n \\n \\n \\n \\nPersonal Details: \\n \\nFirst Name: Gaddam \\nLast Name: Krishna Chaitanya. \\nFather’s Name: Gaddam Anandam. \\nGender: Male \\nLanguages Known: English, Telugu, Hindi. \\nPlace of Birth: Hyderabad, Telangana. \\nCountry of Birth: India \\nNationality: Indian \\n \\nDeclaration : \\n \\nI, Gaddam Krishna Chaitanya, hereby declare that the Information \\nfurnished above is true to the best of my knowledge and belief. \\n \\n \\nPlace: Hyderabad                                                                    Signature : \\n                                                                                           '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 0}, page_content=' \\nM.V. Mani  Rohith  \\n+91 9390222955  • mani.rohith1122@gmail.com  • www.linkedin.com/in/mani -rohith1122  \\n \\n \\nEDUCATION  \\nGITAM  University  | Hyderabad  \\nBachelor’s Degree in Computer Science and Engineering  Aug 2020  - Apr 2024 \\nCGPA: 8.03 /10 \\nURBANE  JUNIOR  COLLEGE  \\nSenior Secondary Education  Jun 2018  - Mar 2020 \\nScore: 821/1000  \\n \\nPERSONAL EXPERIENCE  \\n \\n  Virtual Internship at Accenture:  \\nTechnologies  used:  Excel.  \\n\\uf0b7 Analysed social media platform dataset using  Microsoft Excel  \\n\\uf0b7 Developed data visualization skills, creating interactive dashboards  \\n\\uf0b7 Effectively communicated insights through data storytelling in a virtual environment  \\n  \\nPROJECTS  \\nAutomated  stroke  prediction  using  machine  learning:  for early  intervention  Mar 2024  \\nTechnologies  used:  Python , HTML,  CSS \\n● Developed  and implemented  a machine  learning  model for  automated stroke  prediction \\nutilizing Python and libraries such as scikit -learn and CATBOOST  \\n● Conducted data analysis and feature engineering to improve model performance.  \\n● Evaluated and optimized model performance using various metrics and techniques.  \\n● Deployed the model using a web -based interface with HTML, CSS, and  Python.  \\n● Utilized version control, data visualization, and collaborated with medical professionals.  \\n \\n \\nAutomated  invigilation  Duties:  Jan 2023  \\nTechnologies:  Python,  SQL,  HTML,  CSS \\n● Created  a website  to allocate  invigilation  duties  for faculty  in university  \\n● Briefly  introduce the  automated  invigilation  project,  emphasizing  its goal to  improve  efficiency \\nand reduce manual workload.  \\n● Created a user -friendly interface using HTML, CSS, and Python for faculty members to view \\nand manage their duties  \\n● Improved efficiency and productivity by automating the invigilation duty allocation process  \\nNov 2022  \\nWebpage  on photographic  page:  \\n● Designed  a web page  to showcase few  of my  collections.  \\n● Created  a visually  appealing  and user-friendly  photographic  webpage  using  HTML,  CSS \\n● Implemented  database  functionality  for the webpage  using  technologies  like MySQL  ensuring \\nefficient storage and retrieval of collection information.  \\n \\n'), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mani ROhith Resume .pdf', 'page': 1}, page_content=' \\n \\nTECHNICAL  SKILLS  \\n \\nProgramming  Languages : \\n\\uf0b7 HTML,   \\n\\uf0b7 CSS,   \\n\\uf0b7 Python,   \\n\\uf0b7 Java , \\n\\uf0b7  SQL \\n\\uf0b7 Machine Learning  \\n\\uf0b7 NLP \\n\\uf0b7 Data Science  \\n\\uf0b7 Power Bi  \\n \\nMicrosoft : MS word, MS  excel  and MS PowerPoint.  \\nCERTIFICATIONS  \\n● Internpe  – Python  Programming.  \\n● IBM intro  into Data  Analytics  – data analytics.  \\n● Internshala  – Web  development.  \\n● Accenture – Virtual Internship on Data Analytics and Data Visualization  \\n \\nACHIEVEMENTS  \\n● Awarded  a 25% fee scholarship  at GITAM  University  based  on exceptional \\nperformance in the  entrance exam.  '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mohit Resume.pdf', 'page': 0}, page_content='Songa Mohit Sukumar \\nB.Tech Electrical and Electronics Engineering \\nEmail  : songamohitsukumar@gmail.com  \\nPhone  : 9502297888 \\nAddress : Hyderabad - 500013  \\n \\nACADEMIC DETAILS  \\nCOURSE SPECIALIZATION  INSTITUTE/COLLEGE BOARD/UNIVERSITY SCORE \\n(CGPA) YEAR \\nUnder \\nGraduation Electrical \\n&Electronics \\nEngineering Malla Reddy Institute of \\nEngineering and Technology, \\nHyderabad Jawaharlal Nehru Technological \\nUniversity, Hyderabad 6.74 2023 \\nCLASS XII MPC Triveni Junior College, \\nJangareddigudem Board of Intermediate \\nEducation, A.P 7.36 2019 \\nCLASS X  Triveni High School, \\nJangareddigudem Board of Secondary Education, \\nA.P 9.70 2017 \\n \\nOBJECTIVE To secure a challenging position in a reputable organization where I can make best of my potential by expanding \\nmy learnings, skills and knowledge while making a significant contribution to the success of the company. \\n \\nSUMMER INTERNSHIP / WORK EXPERIENCE  \\nIntern (Electrical Vehicles) in Hyderabad Institute of Electrical Engineers \\n \\nPROJECTS \\nLibrary management system using RFID:  \\nThis Libraries are very important aspects for humans. They are essential in acquiring and retaining the knowledge of a person. But \\nthe earlier library system has caused many problems. This project helps to identify the large number of tagged books using radio \\nwaves. The database shows the availability of the book in the library so that the student can search in the database and if available, \\nthey can collect book from the library. It helps to handle the issue, renewal and return process via RFID tags easily. Student will \\nget notified about the due date of book using GSM. If the student failed to return the book after the due date corresponding fine \\nwill be generated based on the time Period. RFID system is used for theft detection at the library. \\n \\nPower flow improvement in transmission lines in UPFC: \\nThis project proposes a brand new real and reactive power coordination controller for a Unified Power Flow Controller (UPFC). \\nThe fundamental control for the UPFC is such that the series converter of the UPFC controls the transmission line real/ reactive \\npower flow and the shunt converter of the UPFC controls the UPFC bus voltage/shunt reactive power and the DC link capacitor \\nvoltage. In constant state, the real power demand of the series converter is offered with the aid of the shunt converter of the UPFC. \\nTo prevent instability/lack of DC link capacitor voltage for the duration of transient conditions, a new real power coordination \\ncontroller has been designed. The need for reactive power coordination controller for UPFC arises from the fact that excessive bus \\nvoltage (the bus to which the shunt converter is hooked up) excursions occur throughout reactive power transfers. A brand-new \\nreactive power coordination controller has been designed to limit excessive voltage excursions throughout reactive power transfers. \\nMATLAB simulation results had been presented to exhibit the improvement in the efficiency of the UPFC manage with the \\nproposed actual power and reactive power coordination controller. \\n '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Mohit Resume.pdf', 'page': 1}, page_content=\"TECHINICAL SKILLS \\n\\uf0b7 Python                       : Functions and Modules, Data structures \\n\\uf0b7 Machine Learning     : EDA Process, Supervised Learning, Unsupervised learning, NLP \\n\\uf0b7 SQL                           : Data types, Functions,, Joins and subqueries, Indexes. \\n\\uf0b7 OOPs Concept \\n\\uf0b7 MATLAB \\n\\uf0b7 PSIM \\n\\uf0b7 Power Bi \\n  \\n \\nSOFT SKILLS \\n\\uf0b7 Analytical skills \\n\\uf0b7 Problem Solving \\n\\uf0b7 Interpersonal Communication  \\n\\uf0b7 Decision-making \\n\\uf0b7 Team collaboration \\n \\nCERTIFICATIONS \\n\\uf0b7 Certificate of Internship : Completed the ELECTRICAL VEHICLES Internship (11/2021 - 12/2021) in Hyderabad Ins Ɵtute \\nof Electrical Engineers.  \\n\\uf0b7 Certificate of Participation  for attending GENOS'22- A National Level Technical Symposium and participated in trivia \\nquiz conducted by Department of Chemical Engineering Under JNTUH. \\n \\nEXTRA CURRICULAR ACTIVITIES \\n\\uf0b7 Served as a Class Representative  \\n\\uf0b7 Lead  a  team for TECHNOSTAV - 2K23 with 200+ participants \\n \\nPERSONAL INFROMATION \\nDOB: 24/07/2002 \\nMarital Status: Unmarried \\nNationality: Indian \\n \\nLANGUAGES KNOWN \\nEnglish \\nTelugu \\nHindi \\nDECLARATION  \\nI hereby declare that all the information given above is true and correct to the best of my knowledge. \\n \\n \\n \\n \\n \\nMOHIT SUKUMAR SONGA \"), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naga Chaitanya CV.pdf', 'page': 0}, page_content='2020 - 2024\\n2018 - 2020\\n2018V ankam Naga Chaitany a\\nSr Nagar Hy der abad T elangana\\n8978217941  | nagachaitany a1811@gmail.com\\nObjectiv e\\nRecent gr aduate seeking an entr y-le v el r ole in Data Science and Ar tiﬁcial Intelligence t o le v er age my analytical\\nskills and technical knowledge. Eager t o contribute t o inno v ativ e pr ojects, learn cutting-edge technologies, and\\ndeliv er data-driv en solutions while continuously gr owing and de v eloping my exper tise in the ﬁeld. P assionate\\nabout tr ansforming complex data int o actionable insights and suppor ting or ganizational success thr ough AI and\\nML applications\\nE ducation\\nDr .M.G.R E ducational and Reaser ch Institute\\nB T ech || Computer Science Engineering\\n8.54\\nSri Saty a Sai Jr College\\nIntermediate\\n9.31\\nZPHS High School\\nSecondar y E ducation\\n8.7\\nSkills\\nPr ogr amming languages : P ython || SQL || Object oriented pr ogr amming || Html & Css\\nLibr aries : P andas || Nump y || Matplotlib || seaborn\\nMachine Learning: Model T r aining || Implementation || Algorithmic Pr oblem Solving\\nData Analysis : Statistical Modeling\\nT ools and T echnologies: GitHub || Jup yter Note book\\nPr ojects\\nFlight Tick et Price Pr ediction\\nT ools & T echnologies Used : P ython, P andas, NumP y , Scikit-Learn, Matplotlib\\nPr oject Implementation : De v eloped a machine learning model t o pr edict flight tick et prices b y analyzing\\na dataset of 300,153 r ecor ds, incorpor ating f eatur es lik e airline, depar tur e/arriv al times, and flight dur ation.\\nOutcome : Achie v ed 89% accur acy , pr o viding actionable insights for optimizing pricing str ategies and\\nfor ecasting tick et costs eff ectiv ely .\\nDriv er Dr owsiness Detection\\nT ools & T echnologies Used :  P ython, OpenCv ,E y e blink sensor , Alcohol sensor ,webcam\\xa0\\nAlogorithm used  : Haar Cascade F r ontal F ace Algorithm\\xa0\\nLibr ar y used : Dilib libr ar y - for detecting facial landmarks Ther e ar e 68 facial landmarks ar e ther e inside the\\nLibr ar y it co v ers all the face or ganisms\\xa0\\nLanguages\\nEnglish T elugu T amil\\nCer tiﬁcations\\nP ython full stack course completion cer tiﬁcate - Study online\\nMachine learning  Cer tiﬁcate - NPTEL\\nW eb de v elopment \\xa0\\nSoft Skills\\nPr oblem solving ,Quick learner ,Time management,T eam pla y er\\xa0'), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naga Chaitanya CV.pdf', 'page': 1}, page_content=''), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Naliniresume.pdf', 'page': 0}, page_content=\"Nalini Banki  \\n 8328477005   bnalini 243gmail.com     \\n      https://www.linkedin.com/in/nalini -b-959506236/  \\nTechnical Skills   \\nLanguages and Data base: Python, Pandas, Num Py, SQL  \\nVisualization Tools : Power BI  \\nOther Skills : Advanced Excel, Data Analysis  \\nExperience/ Projects  \\n \\nRecession Analysis Project: Impact on the IT Industry  \\n• Conducted a comprehensive analysis of the IT sector's performance during economic recessions over the past \\ndecade.  \\n• Examined key economic indicators such as GDP and unemployment rates to identify trends.  \\n• Developed interactive dashboards in Power BI  for data visualization, resulting in a  90% stakeholder  \\nsatisf action rate based on feedback.  \\n• Provided strategic recommendations for IT companies , to navigate challenges during economic downturns.  \\n• Findings emphasized the importance of proactive strategies for business resilience . \\n \\nStock Market Portfolio Optimization  \\n• Optimized stock portfolios using historical market data, targeting a 15% increase in projected returns . \\n• Utilized Python  and the  PyPortfolioOpt library , achieving a 10% reduction in portfolio risk  based on \\nhistorical volatility analysis.  \\n• Created interactive dashboards in Power BI that enhanced decision -making, with 85% of users reporting \\nimproved investment strategies.  \\n• Gained deeper understanding of financial metrics and risk management principles through practical \\napplication.  \\nHolistic Wellness Tracking: Stress Detection Using Machine Learning  \\n• Leveraged natural language processing (NLP) to analyze over 1,000 Reddit posts  related to mental health for \\nstress detection.  \\n• Applied sentiment analysis and implemented machine learning models, achieving an 80% accuracy  in \\nclassifying stress -related content.  \\n• Identified high -stress subreddits, providing insights that led to a 25% increase  in engagement for mental \\nhealth support resources.  \\n• Utilized Pandas and Matplotlib  for data visualization, effectively communicating findings to stakeholders, \\nwith 90% approval  for actionable insights.  \\n• Paved the way for targeted wellness strategies based on user -generated content insights.  \\n     Training /Certifications  & Acheivements   \\n• Completed a Workshop on Data Analytics with Python : Gained practical experience in data \\nmanipulation, visualization, and statistical analysis using Python libraries like Pandas, NumPy, and \\nMatplotlib.  \\n• Udemy Certification in Python Programming : Acquired in -depth knowledge of Python \\nprogramming fundamentals, including data structures, algorithms, and object -oriented programming, \\nwith applications in data analysis.  \\n• Developed a Portfolio Webpage : Built a personal website showcasing academic and project work.  \\n  Educat ion \\n \\nVijaya Institute of Technology          Jan 2020 -May 2024  \\nBachelor of Technology in Computer S cience and Engineering    Vijayawada,AP.  \\n \\n\"), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Om Shewale Resum.pdf', 'page': 0}, page_content='OM SHEWALE\\n+91-9146412533 | omshewale20195@gmail.com\\n/linkedinom-shewale | /githubomshewale20195e |\\nNashik, Maharashtra - 423301, India\\nOBJECTIVE\\nLooking for a challenging role in Machine Learning and Artificial Intelligence where I can work on different\\nalgorithms, data analysis, model development, algorithm optimization. Looking to work on cutting edge AI solutions\\nand help solve real-world problems with working experience related to AI-driven optimisation, predictive analytics,\\nnatural language processing (NLP) and deep learning in an environment where I can continually improve my\\nskill-set(timeseries analysis, bert word embedding etc).\\nEDUCATION\\n•Savitribai Phule Pune University April - 2024\\nBBA(CA) Malegon(Nashik), INDIA\\n◦CGPA: 7.45/10.00\\n•Gov. Ashram March - 2021\\nPre-University Education Dahindule(Nashik),INDIA\\n◦Percentage: 78.30\\n•K K wagh Vidhyabhavan March - 2019\\nSecondary Education Bhausahebnagar(Nashik), INDIA\\n◦Percentage: 64.40\\nPROJECTS\\n•Project A: Machine Learning Prediction Model for SpaceX Launches Jun- 2024\\nTools: Python, SQL, Jupyter Notebook, Pandas, NumPy, Matplotlib, Plotly, Streamlit [/github]\\n◦Developed a machine learning prediction model for SpaceX launches, utilizing historical data to forecast launch\\nsuccess.\\n◦Implemented data collection techniques using APIs and web scraping for comprehensive datasets, achieving a 95%\\ndata completeness rate.\\n◦Created interactive visualizations using Plotly and Streamlit, ensuring enhanced user engagement and data\\ninterpretation for stakeholders.\\n◦Applied exploratory data analysis (EDA) methods to analyze launch site locations, identifying key factors\\ninfluencing launch success rates.\\nSKILLS\\n•Programming Languages: Python, SQL, HTML, CSS\\n•Web Technologies: HTML, CSS\\n•Database Systems: MySQL, SQLite\\n•Data Science & Machine Learning: Pandas, NumPy, Matplotlib, Scikit-learn, Power BI, Excel\\n•DevOps & Version Control: Git, GitHub\\n•Specialized Area: Data Science, Machine Learning, Data Analytics, Predictive Modeling\\n•Mathematical & Statistical Tools: Statistics, Probability, Linear Algebra\\n•Other Tools & Technologies: Microsoft Excel, Power BI\\n•Research Skills: Data Analysis, Model Development, Feature Engineering, Data Visualization\\nCERTIFICATIONS\\n•Hackerank Aug - 2024\\nADDITIONAL INFORMATION\\nLanguages: English , Hindi , Marathi\\nInterests: Machine Learning and AI ,Data Science and Analytics , Natural Language Processing (NLP) , Predictive\\nModeling and Forecasting'), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 0}, page_content='Prathigudupu  Jyothi  \\n \\n     (+91)  9347792387                                                             https://www.linkedin.com/in/jyothi -prathigudupu -\\n140715289   \\njyothiprathigudupu@gmail.com  https://github.com/JyothiPrathigudupu  \\n  \\n \\n   CAREER  OBJECTIVE  \\nSeeking  a data scientist  role at an innovative  firm valuing  analytics,  coding,  and passion  for data. Eager  to tackle  \\nbig projects  with the latest  tech and enhance  skills  in statistics,  machine  learning,  Artificial  Intelligence  and data \\nvisualization. Ready to collaborate, address challenges, and drive data -informed decisions, with a commitment  \\nto continuous  learning.  \\n \\nTECHNICAL  SKILLS  \\n \\nPython  : Functions and Modules, Data Structures, OOPs, NumPy, Pandas , Matplotlib,  Seaborn,  \\nScikit -learn . \\nMachine  Learning  :  EDA,  Supervised  Learning,  Unsupervised  Learning,  Ensemble  Techniques,  Optimization     \\nTechniques,  Encoding  Techniques,  NLP,  Neural  Networks.  \\nDatabase  : SQL  \\nSoftware  Tools  : Visual  Studio,  Jupyter  Notebook,  Arduino.  \\nData  Analysis  Tools  : Excel,  Power  BI. \\nSpecialized  Area  : Data Science , Data  Analysis . \\nArea  of Interest  : Mathematics,  Statistics,  Data  Science,  Machine  Learning  & Digital  Electronics.  \\nOffice Skills               : MS Word, PowerPoint . \\n \\n \\n \\n \\nEDUCATIONAL  QUALIFICATIONS  \\n \\nB. Tech [Electronics  & Communication  Engineering]  8.11 CGPA  \\nDuring  2020  to 2024  from  Chirala  Engineering  College,  Chirala. (JNTUK)  \\n \\nIntermediate  [Maths,  Physics  & Chemistry]  9.5 CGPA  \\nDuring  2018  to 2020  from Sri Chaithanya  Junior  College,  Repalle.  \\n \\n10th Standard  9.3 CGPA  \\nDuring  2017 -2018  from Vikas  High  School,  Nizampatnam.  \\n \\nINTERNSHIP  AND TRAINING  \\n \\nTraining and Internship on Data  Science  with  Generative -AI (June -Dec 2024 -till date)  \\nQuality  Thought  Infosystems  India  (P) Ltd. \\n \\nInternship  on VLSI  Design  using  Verilog  (Feb -Apr 2024 -till date)  \\nMaven  Silicon  Softech  Pvt. Ltd.  \\n \\nInternship  on Embedded  System  (May -July 2023 -till date)  \\nSun Square  Technologies  Pvt. Ltd \\n \\n \\n'), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\P JYOTHI_Resume-3.pdf', 'page': 1}, page_content=\" \\n \\nPROJECTS  \\n \\nBank  locker  System  using  Embedded  System  \\nProgramming  Language  and Tools  used:  C, Arduino  Software.  \\nDescription: developed a secure door -locking system for bank lockers utilizing RFID and GSM technology,  \\ncombined  with IR sensors.  The system  is designed  to ensure  safe and automated  access  to lockers.  RFID  cards,  \\nsimilar to ATM cards, are used for user authentication, allowing authorized individuals to open and close the  \\nlocker by scanning their card. Additionally, a GSM module sends real -time notifications to users mobile  \\ndevices,  alerting  them  of any access  attempts,  whether  authorized  or unauthorized.  The system  also \\nincorporates IR sensors that detect motion, triggering automatic locking or unlocking based on the user's  \\nproximity. This project highlights my ability to integrate various technologies to create a robust and secure  \\naccess  system.  \\nResponsibilities : Responsible for managing the connections and integration between RFID, GSM, and IR sensor  \\ntechnologies  to ensure  smooth  communication and  functionality within  the secure  door-locking  system.  \\nDesign  & Implementation  of Multiplier  Using  5-3 & 15-4 Compressors (Major  Project)  \\nProgramming  Language  and Tools  used:  Verilog,  Xilinx Vivado  18.1 Software  \\nDescription:  Designed  and implemented  a 16x16  bit multiplier  using  advanced  5-3 and 15-4 compression  \\ntechniques to optimize performance, focusing on reducing delay, computation time, and power consumption.  \\nThis optimization aimed to enhance efficiency for large data storage applications, such as image processing,  \\naddressing  previous  challenges  with high  delay, time,  and power  usage, while  maintaining  data quality.  \\nResponsibilities: Executed and coded the design of a 16x16 bit multiplier using 5 -3 and 15 -4 compression  \\ntechniques, optimizing performance by reducing delay, time, and power consumption for large data storage  \\napplications  like image  processing.  \\nChess  Match  Outcome  Prediction  \\nProgramming  Language  and Tools  used:  Python,  Scikit -learn,  Visual  Studio.  \\nDescription: Developed a machine learning model to predict the chances of victory between two chess players  \\nusing features like player names, number of tournaments, match results (win, loss, draw), and the start and end  \\ndates of games. First, calculated ELO scores for the players  which based  on results , which were then used to \\nestimate probabilities  like White/Black win, draw, and loss, as well as biases towards each player (White Bias, \\nBlack Bias). Other  features included direct match results, results against common opponents, and various \\nELO -based metrics.  Processed chess game data from JSON files, combined it with historical ELO ratings, and \\ncreated additional  game -related features. Applied machine learning models and fine -tuned them usin g \\noptimization  techniques  to improve accuracy. Used Plotly and SHAP to visualize trends and understand which \\nfeatures were mos t important for improving model performance.  \\nResponsibilities : Processed and integrated chess game data from JSON files, utilizing match results and time \\ncontrols to engineer features such as ELO scores, win/loss probabilities, and player biases. Applied machine \\nlearning models and optimized them for improved accuracy . \\n \\nCERTIFICATIONS  \\n \\n• Microsoft  365 Certified:  Teams  Administrator  Associate.  \\n• Certified  Embedded  System  Intern  from  Sun Square  Technologies.  \\n• Certified  CMOS  Digital  VLSI  Design  from  NPTEL.  \\n• Certified  Data Science  Intern  from  Pantech  e Learning.  \\n• Certified  VLSI  Design  using  Verilog  Intern  from  Maven  Silicon . \\n \\n \\nDECLARATION  \\nI hereby  declare  that the above -mentioned  details  are true to the best of my knowledge  and I am \\nresponsible  for any kind of  approach.  \\n \\nDATE:  \\nPLACE:  HYDERABAD  P. JYOTHI  \"), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\pranaya resume.pdf', 'page': 0}, page_content=''), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Rajasri_Resume.pdf', 'page': 0}, page_content=\"  Rajasri Gudikandula       \\nrajasrig.0101 @gmail.com | +91-9440693452  | Hyderabad , India  |www.linkedin.com/in/rajasri -gudikandula -a98548329  \\n \\n \\nA highly motivated and enthusiastic fresher with a strong passion for software development and a solid understanding \\nof programming fundame ntals, including Pytho n and data structures. A pply my academic knowledge and problem -\\nsolving skills in a practical, real -world setting. Committed to continuous learning and personal growth, with a keen \\ninterest in contributing to innovative projects.  Seeking an entry -level position to begin my career in software \\ndevelopment and grow alongside a dynamic team.  \\n \\nSkills:  \\n  Python    : Pandas, NumPy, Matplotlib  \\n  OOP s     : Inheritance, Polymorphism, Encapsulation, Object, Class, Abstraction.  \\n  SQL       : Data Types, Functions, Joins  \\n  Machine Learning  : Linear Regression, Logistic Regression, Decision Tree  \\n  Excel  \\n  PowerBI  \\n \\nCertifications:  \\nCertificate of participation for attending GENOS’22 – A National Level Technical  Symposium  and trivia  quiz \\nconducted  by Department  of Chemical  Engineering  Under  JNTUH . \\n \\nProjects:  \\nLibrary  Management  System  using  RFID   Sep 2022 – Jan 2023  \\nThis library management system is software that is designed to manage all the functions of a library. It helps librarian \\nto maintain the database of new books and the books that are borrowed by members along with their due dates. This \\nsystem completely automates all your library's activities.  \\n \\nPower Flow Improvement in Transmission L ines using UPFC                                 March 2023 – July 2023  \\nThe UPFC, by means of angularly unconstained series voltage injection, is able to control, concurrently or \\nselectively,    the transmission line voltage, impedance, and angle or, alternatively, the real and reactive power \\nflow in t he line. the UPFC may also provide independently controllable shunt reactive compensation.  \\n \\nPredictive Modeling with XGBoost and Logistic Regression  \\nThe implementation of predictive models using Logistic Regression and XGBoost classifiers.  It includes data \\npreprocessing steps, model training, evaluation using metrics such as R², mean squared error, accuracy, and ROC \\nAUC score. The notebook applies these models to binary classification tasks, compares their performance, and outputs \\npredictio ns \\n \\nEducation:  \\nMalla Reddy Institute of Engineering and Technology , Hyderabad,  India  Aug 2023  \\nBachelor  of  Technology  in Electrical and Electronics Engineering  \\nCoursework:  Machine  Learning,  Statistics, Data Science, Data Visualization.  \\nOrganisation /Activities : Secured  second  place  in Carrom,  Organised  Gaming  Event  in College  Fest \\n \\nRavindra Girls Junior C ollege , Metpally , Telangana, India           May  2019  \\nInter  \"), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Siva Rama Krishna.pdf', 'page': 0}, page_content='PENDLI SIVA RAMA KRISHNA  \\n1-46, Rayavaram, Guntur, Andhra \\nPradesh – 522426                                                             \\nPhone: 9346455348  Email: \\npendlisivaramakrishna@gmail.com  \\nLinkedIn: siva -rama -krishna -pendli  \\nPROFESSIONAL SUMMARY  \\nData Analyst with a solid foundation in data science, statistical analysis, and machine \\nlearning. Proven expertise in Python, SQL, and data -driven decision -making. Adept at \\ntransforming raw data into meaningful i hnsights to drive strategic decisions. Seeking to \\nleverage academic and project experience in a challenging data analyst role.  \\nSKILLS SUMMARY  \\no Languages: Python , SQL,HTML,CSS,,J avaScript ,Django ,Machine learning.  \\no Frameworks: Pandas, NumPy , Scikit -Learn, Matplotlib\\nEDUCATION   \\n• Kalasalingam Academy of Research and Education, Chennai India  \\nBachelor of Technology in Computer Science and Engineering               CGPA: 7.36  \\nJune 2020 - August 2024  \\n• Sri Chaitanya Institutional Education, Hyderabad India  \\nIntermediate - M.P.C                                                                                               CGPA: 8.32  \\nJune 2018 - August 2020  \\n• Geetha Gurukulam High School, Kodad India  \\nSecondary School                                                                                                     CGPA: 7.8  \\nJune 2017 - May 2018  \\nPROJECTS  \\n• YouTube Comment Spam Detection with UI  \\n- Built a machine learning model to detect spam in YouTube comments using NLP \\nfor text analysis and feature extraction. Technologies : Python, Flask, Sklearn, NLP  \\n• News Headline Generator Using NLP  \\n- Developed a headline generation model for news articles using sequence -to-\\nsequence learning models and Transformers. Technologies : Python, TensorFlow, \\nNLP, Transformers  \\n• Pediatric Healthcare Analysis Using Machine Learning  \\n- Conducted analysis of pediatric healthcare data, applying clustering techniques \\nand decision trees. Technologies : Python, Pandas, Scikit -learn  '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Siva Rama Krishna.pdf', 'page': 1}, page_content=' \\nCERTIFICATES  \\n• Completed an Internship provided by AICTE  \\n• Published  a research paper titles “Pedi atric Healthcare Analysis Using Machine \\nLearning ” in IEEE Conference.  \\n• Published a research paper  titled \"Youtube Comment   Spam Detection with UI\" in  \\nIEEE  Conference.  \\nHOBBIES  \\n• Cricket.  \\n• Cooking.  \\n• Problem Solving.  \\n• Dancing.  \\nLANGUAGES  \\n• Telugu . \\n• English.  \\n• Tamil.  \\n '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 0}, page_content='SREEDHAR BALINA\\nFresher\\nbalinasreedhar99@gmail.com +91 9652469123 SR Nagar, Hyderabad, 500038 \\n05/09/2002 INDIAN github.com/sreedhar1227 \\nlinkedin.com/in/balina-sreedhar-3432a5212 \\nProfile\\n“To obtain an entry-level position in a reputed organization where I can apply my skills and \\nknowledge in Data Science with Generative AI to innovative projects and further develop my \\nexpertise in this field”\\nEducation\\nBachelor of Technology, Computer Science\\nJain University08/2020 – 05/2024\\nBengaluru, India\\nHigher Secondary School Certificate\\nSri Chaitanya05/2019 – 06/2020\\nVijayawada, India\\nSecondary School Certificate\\nDR KKR Gowtham06/2017 – 05/2018\\nGuntur, India\\nSkills\\nPython MySQL Data Science with Generative AI Microsoft Excel\\nMachine Learning Deep Learning with Keras and TensorFlow Computer vision\\nNatural Language Processing (NLP) Data Structures and Algorithms\\nPROBABILITY AND STATISTICS Power bi Tableau Data Visualization\\nLanguages\\nEnglish Telugu\\nbalinasreedhar99@gmail.com 1 / 2'), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\SREEDHAR RESUME.pdf', 'page': 1}, page_content=\"Certificates\\nData Science\\nRemark Skill Technical \\nWorkshop on Data Science in \\nAssociation with FCC, IIT \\nHyderabad\\nProjects\\n1) Voice Classification to identify the voice of male and female based upon acoustic \\nproperties of the voice and speech\\nThis database was created to identify a voice as male or female, based upon acoustic \\nproperties of the voice and speech. The dataset consists of 3800 recorded voice samples.\\n2) Decision Tree Classifiers Using Bank Dataset to Predict weather a person is eligible for \\nlone amount.\\nDecision Tree Classifiers are powerful tools for both classification and regression tasks, \\nknown for their interpretability and ability to model non-linear relationships. However, their \\nsusceptibility to overfitting and instability requires careful tuning and sometimes \\nintegration with ensemble methods like Random Forests or Gradient Boosting Machines to enhance \\nperformance and generalization.\\n3) Heart attack analysis\\nWe have data on patients seen by a cardiologist. The main goal of this project is to build a \\nmachine learning model, that will be able to predict the risk of a heart attack based on a \\npatient's health condition.\\nDeclaration\\nSreedhar Balina, solemnly declare that the information presented in this resume is true,\\naccurate, and complete to the best of my knowledge and belief\\nSreedhar\\xa0Balina\\nHyderabad\\nbalinasreedhar99@gmail.com 2 / 2\"), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\Sudheer_Resume.pdf', 'page': 0}, page_content=' \\n \\nCONTACT   \\n• pavansudheerbyrapuneni28@gmail.com  \\n• +91 9182165783  \\n• 2-191, Vemparala, Addanki, \\n Andhra Pradesh, 523201  \\n \\nWORK EXPERIENCE  \\n Fresher  \\n \\n  PA V AN SUDHEER  \\nBYRAPUNENI  \\nMACHINE LEARNING ENGINEER  \\nI am passionate about developing machine learning models that are \\nboth highly accurate and efficient, and always strive to create solutions \\nthat deliver meaningful insights and enhance user experiences. My \\ngoal is to leverage data -driven approaches to solve complex problems \\nand contribute to innovative projects that make a positive impact. \\n \\nSKILLS    \\n• Python  \\n• SQL  \\n• Machine Learning  \\n• Data Structures and algorithms  \\n• Object Oriented programming \\n• Statistics  \\n• Good communication skills  \\n EDUCATION  \\nBACHELOR OF TECHNOLOGY \\nIN COMPUTER SCIENCE  \\nVishnu Institute Of Technology                          \\nAugust 2019 – June 2023  \\n8.08 CGPA  \\nSENIOR SECONDARY  \\nSri Chaitanya Junior College          \\nAugust 2016 – June 2018 \\n9.65 CGPA  \\nSECONDARY  \\nSri Chaitanya Techno School                                                                       \\nAugust 2015 – June 2016  \\n10.0 CGPA  \\n PROJECT :  Predictive Analytics for Insurance Claims and Costs  \\n \\nDESCRIPTION : Developed and implemented machine learning \\nmodels to enhance decision -making processes in an insurance \\ncompany. The project focused on predicting various key metrics such \\nas claim amounts, length of hospital stays, premium pricing, risk \\nscores, and pharma cy costs. By leveraging regression techniques, the \\nmodels provided accurate and actionable insights, significantly \\nimproving operational efficiency and financial planning.  \\n \\nRESPONSIBILITIES :   \\n• Data Collection and Preprocessing  \\n• Feature Engineering  \\n• Model Deve lopment  \\n• Model Evaluation \\n• Reporting and Visualization \\n '), Document(metadata={'source': 'C:\\\\Users\\\\nr802\\\\Downloads\\\\GenAI Projects\\\\RESUMESP\\\\yuvaraj.pdf', 'page': 0}, page_content=' \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nGET IN TOUCH!  \\nMobile:  +91-9381071866  \\nEmail: yuvarajnaikk663@gmail.com  \\n \\n \\nPERSONAL  DETAILS  \\n Current Location  Hyderabad  \\n Date of Birth  May 12, 2000 \\n Gender  Male \\n \\n \\nSKILLS  \\n Python  \\n Data Analytics \\n Power BI  \\n SQL \\n \\n \\nLANGUAGES  KNOWN  \\n         Engli sh  \\nTelugu   \\n \\n \\nACHIEVEMENTS  \\n Received scholarship in B.Sc  \\n Top 3 in class,  Received  scholarship  in \\nschool  Course  MBA/PGDM  (Finance)  \\nCollege  JNTU  College  of Engineering,  Anantapur,  Anantapur \\nScore  7% \\nGraduation  \\nCourse  B.Sc (Computers)  \\nCollege  Anu Bose Institute of Technology, palvancha \\nScore  8.5% \\nClass  XII \\nBoard  Name  Other  \\nMedium  English \\nYear of Passing  2019 \\nPercentage  75% \\nClass  X \\nBoard  Name  Other  \\nMedium  English \\nYear of Passing  2017 \\nPercentage  82% \\n \\nPROJECTS  \\n    Portfolio  management  , November  2023  - March  2024  \\n Portofolio management  is the art of selecting and overseeing a group  of investment \\nthat meet  the long-term  financial  objectives  and risk tolerance  of a client,a  Company,  or \\nan Institution  \\n \\n \\n ')]\n"
     ]
    }
   ],
   "source": [
    "# In the /upload/ endpoint\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d6e58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from fastapi.responses import JSONResponse\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
